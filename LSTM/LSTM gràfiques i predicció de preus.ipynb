{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dfb2271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Procesando: Amazon_Stock_Price_output =====\n",
      "  ✓ Parámetros cargados: layers=1, units=512, dropout=0.1, lr=0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 12 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Pesos cargados desde: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_LSTM\\Amazon_Stock_Price_output\\Amazon_Stock_Price_output_best_weights.weights.h5\n",
      "  → Test MAE=4.5752, RMSE=5.7316, R²=0.9283\n",
      "  ✓ Métricas guardadas en: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_LSTM\\Amazon_Stock_Price_output\\Amazon_Stock_Price_output_metrics_test.csv\n",
      "  ✓ Gráfica Test guardada en: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_LSTM\\Amazon_Stock_Price_output\\Amazon_Stock_Price_output_test_plot.html\n",
      "  ✓ Predicciones futuras guardadas en: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_LSTM\\Amazon_Stock_Price_output\\Amazon_Stock_Price_output_future_10days.csv\n",
      "  ✓ Gráfica futura guardada en: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_LSTM\\Amazon_Stock_Price_output\\Amazon_Stock_Price_output_future_plot.html\n",
      "\n",
      "===== Procesando: Euro_Stoxx_50_Stock_Price_output =====\n",
      "  ✓ Parámetros cargados: layers=1, units=256, dropout=0.5, lr=0.001\n",
      "  ✓ Pesos cargados desde: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_LSTM\\Euro_Stoxx_50_Stock_Price_output\\Euro_Stoxx_50_Stock_Price_output_best_weights.weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning:\n",
      "\n",
      "Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 12 variables. \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Test MAE=51.0807, RMSE=64.9371, R²=0.7725\n",
      "  ✓ Métricas guardadas en: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_LSTM\\Euro_Stoxx_50_Stock_Price_output\\Euro_Stoxx_50_Stock_Price_output_metrics_test.csv\n",
      "  ✓ Gráfica Test guardada en: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_LSTM\\Euro_Stoxx_50_Stock_Price_output\\Euro_Stoxx_50_Stock_Price_output_test_plot.html\n",
      "  ✓ Predicciones futuras guardadas en: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_LSTM\\Euro_Stoxx_50_Stock_Price_output\\Euro_Stoxx_50_Stock_Price_output_future_10days.csv\n",
      "  ✓ Gráfica futura guardada en: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_LSTM\\Euro_Stoxx_50_Stock_Price_output\\Euro_Stoxx_50_Stock_Price_output_future_plot.html\n",
      "\n",
      "===== Procesando: Google_Stock_Price_output =====\n",
      "  ✓ Parámetros cargados: layers=1, units=512, dropout=0.5, lr=0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning:\n",
      "\n",
      "Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 12 variables. \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Pesos cargados desde: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_LSTM\\Google_Stock_Price_output\\Google_Stock_Price_output_best_weights.weights.h5\n",
      "  → Test MAE=3.3198, RMSE=4.3153, R²=0.9061\n",
      "  ✓ Métricas guardadas en: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_LSTM\\Google_Stock_Price_output\\Google_Stock_Price_output_metrics_test.csv\n",
      "  ✓ Gráfica Test guardada en: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_LSTM\\Google_Stock_Price_output\\Google_Stock_Price_output_test_plot.html\n",
      "  ✓ Predicciones futuras guardadas en: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_LSTM\\Google_Stock_Price_output\\Google_Stock_Price_output_future_10days.csv\n",
      "  ✓ Gráfica futura guardada en: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_LSTM\\Google_Stock_Price_output\\Google_Stock_Price_output_future_plot.html\n",
      "\n",
      "===== Procesando: Hang_Seng_Stock_Price_output =====\n",
      "  ✓ Parámetros cargados: layers=1, units=256, dropout=0.1, lr=0.001\n",
      "  ✓ Pesos cargados desde: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_LSTM\\Hang_Seng_Stock_Price_output\\Hang_Seng_Stock_Price_output_best_weights.weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning:\n",
      "\n",
      "Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 12 variables. \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Test MAE=348.2261, RMSE=482.8292, R²=0.8913\n",
      "  ✓ Métricas guardadas en: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_LSTM\\Hang_Seng_Stock_Price_output\\Hang_Seng_Stock_Price_output_metrics_test.csv\n",
      "  ✓ Gráfica Test guardada en: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_LSTM\\Hang_Seng_Stock_Price_output\\Hang_Seng_Stock_Price_output_test_plot.html\n",
      "  ✓ Predicciones futuras guardadas en: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_LSTM\\Hang_Seng_Stock_Price_output\\Hang_Seng_Stock_Price_output_future_10days.csv\n",
      "  ✓ Gráfica futura guardada en: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_LSTM\\Hang_Seng_Stock_Price_output\\Hang_Seng_Stock_Price_output_future_plot.html\n",
      "\n",
      "===== Procesando: IBEX_35_Stock_Price_output =====\n",
      "  ✓ Parámetros cargados: layers=1, units=512, dropout=0.5, lr=0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning:\n",
      "\n",
      "Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 12 variables. \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Pesos cargados desde: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_LSTM\\IBEX_35_Stock_Price_output\\IBEX_35_Stock_Price_output_best_weights.weights.h5\n",
      "  → Test MAE=112.6018, RMSE=139.6789, R²=0.8666\n",
      "  ✓ Métricas guardadas en: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_LSTM\\IBEX_35_Stock_Price_output\\IBEX_35_Stock_Price_output_metrics_test.csv\n",
      "  ✓ Gráfica Test guardada en: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_LSTM\\IBEX_35_Stock_Price_output\\IBEX_35_Stock_Price_output_test_plot.html\n",
      "  ✓ Predicciones futuras guardadas en: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_LSTM\\IBEX_35_Stock_Price_output\\IBEX_35_Stock_Price_output_future_10days.csv\n",
      "  ✓ Gráfica futura guardada en: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_LSTM\\IBEX_35_Stock_Price_output\\IBEX_35_Stock_Price_output_future_plot.html\n",
      "\n",
      "===== Procesando: Indra_Stock_Price_output =====\n",
      "  ✓ Parámetros cargados: layers=1, units=512, dropout=0.5, lr=0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning:\n",
      "\n",
      "Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 12 variables. \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Pesos cargados desde: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_LSTM\\Indra_Stock_Price_output\\Indra_Stock_Price_output_best_weights.weights.h5\n",
      "  → Test MAE=234.5538, RMSE=313.4665, R²=0.7487\n",
      "  ✓ Métricas guardadas en: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_LSTM\\Indra_Stock_Price_output\\Indra_Stock_Price_output_metrics_test.csv\n",
      "  ✓ Gráfica Test guardada en: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_LSTM\\Indra_Stock_Price_output\\Indra_Stock_Price_output_test_plot.html\n",
      "  ✓ Predicciones futuras guardadas en: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_LSTM\\Indra_Stock_Price_output\\Indra_Stock_Price_output_future_10days.csv\n",
      "  ✓ Gráfica futura guardada en: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_LSTM\\Indra_Stock_Price_output\\Indra_Stock_Price_output_future_plot.html\n",
      "\n",
      "===== Procesando: P&G_Stock_Price_output =====\n",
      "  ✓ Parámetros cargados: layers=1, units=256, dropout=0.3, lr=0.001\n",
      "  ✓ Pesos cargados desde: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_LSTM\\P&G_Stock_Price_output\\P&G_Stock_Price_output_best_weights.weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning:\n",
      "\n",
      "Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 12 variables. \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Test MAE=2.1416, RMSE=2.6764, R²=0.6456\n",
      "  ✓ Métricas guardadas en: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_LSTM\\P&G_Stock_Price_output\\P&G_Stock_Price_output_metrics_test.csv\n",
      "  ✓ Gráfica Test guardada en: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_LSTM\\P&G_Stock_Price_output\\P&G_Stock_Price_output_test_plot.html\n",
      "  ✓ Predicciones futuras guardadas en: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_LSTM\\P&G_Stock_Price_output\\P&G_Stock_Price_output_future_10days.csv\n",
      "  ✓ Gráfica futura guardada en: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_LSTM\\P&G_Stock_Price_output\\P&G_Stock_Price_output_future_plot.html\n",
      "\n",
      "===== Procesando: S&P500_Stock_Price_output =====\n",
      "  ✓ Parámetros cargados: layers=2, units=128, dropout=0.1, lr=0.001\n",
      "  ✓ Pesos cargados desde: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_LSTM\\S&P500_Stock_Price_output\\S&P500_Stock_Price_output_best_weights.weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning:\n",
      "\n",
      "Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 18 variables. \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Test MAE=71.1080, RMSE=90.2894, R²=0.8303\n",
      "  ✓ Métricas guardadas en: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_LSTM\\S&P500_Stock_Price_output\\S&P500_Stock_Price_output_metrics_test.csv\n",
      "  ✓ Gráfica Test guardada en: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_LSTM\\S&P500_Stock_Price_output\\S&P500_Stock_Price_output_test_plot.html\n",
      "  ✓ Predicciones futuras guardadas en: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_LSTM\\S&P500_Stock_Price_output\\S&P500_Stock_Price_output_future_10days.csv\n",
      "  ✓ Gráfica futura guardada en: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_LSTM\\S&P500_Stock_Price_output\\S&P500_Stock_Price_output_future_plot.html\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "# CONFIGURACIÓN\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "\n",
    "BASE_PATH    = r\"C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\Conjunt de dades Preprocessades\\Datasets\"\n",
    "RESULTS_PATH = r\"C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_LSTM\"\n",
    "DATASETS     = [\n",
    "    \"Amazon_Stock_Price_output.csv\",\n",
    "    \"Euro_Stoxx_50_Stock_Price_output.csv\",\n",
    "    \"Google_Stock_Price_output.csv\",\n",
    "    \"Hang_Seng_Stock_Price_output.csv\",\n",
    "    \"IBEX_35_Stock_Price_output.csv\",\n",
    "    \"Indra_Stock_Price_output.csv\",\n",
    "    \"P&G_Stock_Price_output.csv\",\n",
    "    \"S&P500_Stock_Price_output.csv\"\n",
    "]\n",
    "\n",
    "N_STEPS = 30\n",
    "FEATURE_COLUMNS = [\n",
    "    \"Open\",\"High\",\"Low\",\"Volume\",\n",
    "    \"EMA_7\",\"EMA_40\",\"MACD\",\"Signal_Line\",\n",
    "    \"MACD_Hist\",\"RSI\",\"ATR\"\n",
    "]\n",
    "TARGET_COLUMN = \"Close\"\n",
    "TEST_RATIO = 0.10\n",
    "VAL_RATIO  = 0.10\n",
    "TRAIN_RATIO = 1 - TEST_RATIO - VAL_RATIO\n",
    "\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "# FUNCIONES AUXILIARES\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "\n",
    "def create_sequences(X, y, n_steps=30):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(n_steps, len(X)):\n",
    "        Xs.append(X[i - n_steps:i])\n",
    "        ys.append(y[i])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "def build_lstm_model(sequence_length, n_features, units, n_layers, dropout, learning_rate):\n",
    "    \"\"\"\n",
    "    Reconstruye la arquitectura LSTM con los hiperparámetros dados.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    for i in range(n_layers):\n",
    "        is_first = (i == 0)\n",
    "        is_last = (i == n_layers - 1)\n",
    "        return_sequences = not is_last\n",
    "        if is_first:\n",
    "            model.add(LSTM(\n",
    "                units, return_sequences=return_sequences,\n",
    "                input_shape=(sequence_length, n_features)\n",
    "            ))\n",
    "        else:\n",
    "            model.add(LSTM(units, return_sequences=return_sequences))\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, activation=\"linear\"))\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss=\"huber\", optimizer=optimizer, metrics=[\"mean_absolute_error\"])\n",
    "    return model\n",
    "\n",
    "def compute_metrics(model, X_scaled, y_scaled, scaler_y):\n",
    "    \"\"\"\n",
    "    Calcula MAE, RMSE, R² y devuelve y_true, y_pred.\n",
    "    \"\"\"\n",
    "    y_pred_scaled = model.predict(X_scaled, verbose=0)\n",
    "    y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
    "    y_true = scaler_y.inverse_transform(y_scaled)\n",
    "\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return mae, rmse, r2, y_true, y_pred\n",
    "\n",
    "def recompute_indicators(df):\n",
    "    \"\"\"\n",
    "    Recalcula EMA_7, EMA_40, MACD, Signal_Line, MACD_Hist, RSI, ATR para todo df.\n",
    "    \"\"\"\n",
    "    close = df['Close']\n",
    "    df['EMA_7'] = close.ewm(span=7, adjust=False).mean()\n",
    "    df['EMA_40'] = close.ewm(span=40, adjust=False).mean()\n",
    "\n",
    "    ema_12 = close.ewm(span=12, adjust=False).mean()\n",
    "    ema_26 = close.ewm(span=26, adjust=False).mean()\n",
    "    macd = ema_12 - ema_26\n",
    "    signal = macd.ewm(span=9, adjust=False).mean()\n",
    "    df['MACD'] = macd\n",
    "    df['Signal_Line'] = signal\n",
    "    df['MACD_Hist'] = macd - signal\n",
    "\n",
    "    delta = close.diff()\n",
    "    gain = delta.clip(lower=0)\n",
    "    loss = -delta.clip(upper=0)\n",
    "    avg_gain = gain.ewm(alpha=1/14, adjust=False).mean()\n",
    "    avg_loss = loss.ewm(alpha=1/14, adjust=False).mean()\n",
    "    rs = avg_gain / (avg_loss + 1e-8)\n",
    "    df['RSI'] = 100 - (100 / (1 + rs))\n",
    "\n",
    "    df['ATR'] = (df['High'] - df['Low']).rolling(window=14).mean()\n",
    "\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "# BUCLE PRINCIPAL: CARGAR CADA DATASET, LEER PESOS, GUARDAR MÉTRICAS Y GRAFICAR\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "\n",
    "for filename in DATASETS:\n",
    "    dataset_name = os.path.splitext(filename)[0]\n",
    "    print(f\"\\n===== Procesando: {dataset_name} =====\")\n",
    "\n",
    "    # Rutas\n",
    "    data_path    = os.path.join(BASE_PATH, filename)\n",
    "    model_folder = os.path.join(RESULTS_PATH, dataset_name)\n",
    "    weights_path = os.path.join(model_folder, f\"{dataset_name}_best_weights.weights.h5\")\n",
    "    params_path  = os.path.join(model_folder, f\"{dataset_name}_best_params.json\")\n",
    "\n",
    "    if not os.path.isfile(weights_path) or not os.path.isfile(params_path):\n",
    "        print(f\"  ⚠️ Faltan pesos o parámetros para {dataset_name}, omitiendo.\")\n",
    "        continue\n",
    "\n",
    "    # 1) Cargar CSV original\n",
    "    df = pd.read_csv(data_path)\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df.sort_values(\"Date\", inplace=True)\n",
    "    df = df.dropna(subset=FEATURE_COLUMNS + [TARGET_COLUMN]).reset_index(drop=True)\n",
    "\n",
    "    # 2) Crear secuencias y dividir en train/val/test\n",
    "    data_X = df[FEATURE_COLUMNS].values\n",
    "    data_y = df[TARGET_COLUMN].values.reshape(-1, 1)\n",
    "    X_seq, y_seq = create_sequences(data_X, data_y, n_steps=N_STEPS)\n",
    "\n",
    "    n_total = len(X_seq)\n",
    "    train_end = int(n_total * TRAIN_RATIO)\n",
    "    val_end   = train_end + int(n_total * VAL_RATIO)\n",
    "\n",
    "    X_train = X_seq[:train_end]\n",
    "    y_train = y_seq[:train_end]\n",
    "\n",
    "    X_val = X_seq[train_end:val_end]\n",
    "    y_val = y_seq[train_end:val_end]\n",
    "\n",
    "    X_test = X_seq[val_end:]\n",
    "    y_test = y_seq[val_end:]\n",
    "\n",
    "    # 3) Reconstruir scalers según train+val\n",
    "    scaler_X = MinMaxScaler()\n",
    "    X_train_val_flat = X_seq[:val_end].reshape(-1, len(FEATURE_COLUMNS))\n",
    "    scaler_X.fit(X_train_val_flat)\n",
    "\n",
    "    scaler_y = MinMaxScaler()\n",
    "    scaler_y.fit(y_seq[:val_end])\n",
    "\n",
    "    def scale_X(X):\n",
    "        flat = X.reshape(-1, len(FEATURE_COLUMNS))\n",
    "        flat_scaled = scaler_X.transform(flat)\n",
    "        return flat_scaled.reshape(X.shape)\n",
    "\n",
    "    X_train_scaled = scale_X(X_train)\n",
    "    X_val_scaled   = scale_X(X_val)\n",
    "    X_test_scaled  = scale_X(X_test)\n",
    "\n",
    "    y_train_scaled = scaler_y.transform(y_train)\n",
    "    y_val_scaled   = scaler_y.transform(y_val)\n",
    "    y_test_scaled  = scaler_y.transform(y_test)\n",
    "\n",
    "    # 4) Cargar hiperparámetros\n",
    "    with open(params_path, 'r') as f:\n",
    "        best_params = json.load(f)\n",
    "    n_layers      = best_params['n_layers']\n",
    "    units         = best_params['units']\n",
    "    dropout       = best_params['dropout']\n",
    "    learning_rate = best_params['learning_rate']\n",
    "\n",
    "    print(f\"  ✓ Parámetros cargados: layers={n_layers}, units={units}, dropout={dropout}, lr={learning_rate}\")\n",
    "\n",
    "    # 5) Reconstruir modelo y cargar pesos\n",
    "    model = build_lstm_model(\n",
    "        sequence_length=N_STEPS,\n",
    "        n_features=len(FEATURE_COLUMNS),\n",
    "        units=units,\n",
    "        n_layers=n_layers,\n",
    "        dropout=dropout,\n",
    "        learning_rate=learning_rate\n",
    "    )\n",
    "    model.load_weights(weights_path)\n",
    "    print(f\"  ✓ Pesos cargados desde: {weights_path}\")\n",
    "\n",
    "    # 6) Calcular métricas en Test\n",
    "    mae_test, rmse_test, r2_test, y_true, y_pred = compute_metrics(\n",
    "        model, X_test_scaled, y_test_scaled, scaler_y\n",
    "    )\n",
    "    print(f\"  → Test MAE={mae_test:.4f}, RMSE={rmse_test:.4f}, R²={r2_test:.4f}\")\n",
    "\n",
    "    # 6.1) Guardar métricas en CSV\n",
    "    df_metrics = pd.DataFrame({\n",
    "        \"Dataset\": [dataset_name],\n",
    "        \"MAE\":     [mae_test],\n",
    "        \"RMSE\":    [rmse_test],\n",
    "        \"R2\":      [r2_test]\n",
    "    })\n",
    "    metrics_csv = os.path.join(model_folder, f\"{dataset_name}_metrics_test.csv\")\n",
    "    df_metrics.to_csv(metrics_csv, index=False)\n",
    "    print(f\"  ✓ Métricas guardadas en: {metrics_csv}\")\n",
    "\n",
    "    # 7) Graficar Real vs Predicho (Test)\n",
    "    # --------------------------------------------------\n",
    "    # Primer, calculamos el índice donde empieza el test en df['Date']:\n",
    "    start_test_idx = N_STEPS + val_end\n",
    "    dates_test = df['Date'].iloc[start_test_idx : start_test_idx + len(y_true)].reset_index(drop=True)\n",
    "\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=dates_test,\n",
    "        y=y_true.flatten(),\n",
    "        mode='lines',\n",
    "        name='Real (Close)',\n",
    "        line=dict(color='blue')\n",
    "    ))\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=dates_test,\n",
    "        y=y_pred.flatten(),\n",
    "        mode='lines',\n",
    "        name='Predit',\n",
    "        line=dict(color='red', dash='dash')\n",
    "    ))\n",
    "    fig.update_layout(\n",
    "        title=f\"{dataset_name} – Real vs Predicció (Test, LSTM)\",\n",
    "        xaxis_title='Data',\n",
    "        yaxis_title='Preu (Close)',\n",
    "        template='plotly_white',\n",
    "        xaxis_rangeslider_visible=True\n",
    "    )\n",
    "    plot_html = os.path.join(model_folder, f\"{dataset_name}_test_plot.html\")\n",
    "    fig.write_html(plot_html)\n",
    "    print(f\"  ✓ Gráfica Test guardada en: {plot_html}\")\n",
    "    # --------------------------------------------------\n",
    "\n",
    "    # 8) Predicción autoregresiva de los próximos 10 días laborables\n",
    "    df_future = df.copy().reset_index(drop=True)\n",
    "    recompute_indicators(df_future)\n",
    "\n",
    "    last_sequence = X_test_scaled[-1].copy().reshape(1, N_STEPS, len(FEATURE_COLUMNS))\n",
    "    future_preds = []\n",
    "    future_dates = pd.bdate_range(start=df_future['Date'].iloc[-1] + pd.Timedelta(days=1), periods=10)\n",
    "\n",
    "    for date in future_dates:\n",
    "        # 8.1) Predicción escalada y remapeo a valor real\n",
    "        y_pred_scaled = model.predict(last_sequence, verbose=0)[0][0]\n",
    "        y_pred_real = scaler_y.inverse_transform([[y_pred_scaled]])[0][0]\n",
    "        future_preds.append(y_pred_real)\n",
    "\n",
    "        # 8.2) Añadir la predicción al DataFrame para recalcular indicadores\n",
    "        prev = df_future.iloc[-1]\n",
    "        new_row = {\n",
    "            'Date':        date,\n",
    "            'Open':        prev['Close'],   # asumimos que Open = Close anterior\n",
    "            'High':        y_pred_real,\n",
    "            'Low':         y_pred_real,\n",
    "            'Volume':      prev['Volume'],  # mantenemos igual\n",
    "            'Close':       y_pred_real,\n",
    "            'EMA_7':       np.nan,\n",
    "            'EMA_40':      np.nan,\n",
    "            'MACD':        np.nan,\n",
    "            'Signal_Line': np.nan,\n",
    "            'MACD_Hist':   np.nan,\n",
    "            'RSI':         np.nan,\n",
    "            'ATR':         np.nan\n",
    "        }\n",
    "        df_future.loc[len(df_future)] = new_row\n",
    "        recompute_indicators(df_future)\n",
    "\n",
    "        # 8.3) Extraer las últimas N_STEPS filas de indicadores técnicos\n",
    "        recent_features = df_future[FEATURE_COLUMNS].iloc[-N_STEPS:].values\n",
    "        recent_scaled = scaler_X.transform(recent_features)\n",
    "        last_sequence = recent_scaled.reshape(1, N_STEPS, len(FEATURE_COLUMNS))\n",
    "\n",
    "    # 9) Guardar predicciones futuras en CSV\n",
    "    df_fut_pred = pd.DataFrame({\n",
    "        \"Date\": future_dates,\n",
    "        \"Predicted_Close\": future_preds\n",
    "    })\n",
    "    fut_csv = os.path.join(model_folder, f\"{dataset_name}_future_10days.csv\")\n",
    "    df_fut_pred.to_csv(fut_csv, index=False)\n",
    "    print(f\"  ✓ Predicciones futuras guardadas en: {fut_csv}\")\n",
    "\n",
    "    # 10) Graficar histórico + predicciones futuras\n",
    "    fig_future = go.Figure()\n",
    "    fig_future.add_trace(go.Scatter(\n",
    "        x=df['Date'], y=df['Close'],\n",
    "        mode='lines', name='Històric Close', line=dict(color='lightblue')\n",
    "    ))\n",
    "    fig_future.add_trace(go.Scatter(\n",
    "        x=future_dates, y=np.array(future_preds),\n",
    "        mode='lines+markers', name='Predicción futura',\n",
    "        line=dict(color='orange', dash='dash'),\n",
    "        marker=dict(size=6)\n",
    "    ))\n",
    "    fig_future.update_layout(\n",
    "        title=f\"{dataset_name} – Predicción Pròxims 10 dies\",\n",
    "        xaxis_title='Data',\n",
    "        yaxis_title='Preu (Close)',\n",
    "        template='plotly_white',\n",
    "        xaxis_rangeslider_visible=True\n",
    "    )\n",
    "    fut_html = os.path.join(model_folder, f\"{dataset_name}_future_plot.html\")\n",
    "    fig_future.write_html(fut_html)\n",
    "    print(f\"  ✓ Gráfica futura guardada en: {fut_html}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98486a7a",
   "metadata": {},
   "source": [
    "GENERACIÓ MODEL HÍBRID: LSTM + XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8181016a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Procesant: Amazon_Stock_Price_output =====\n",
      "  ✓ Paràmetres LSTM carregats: layers=1, units=512, dropout=0.1, lr=0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 12 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Pesos LSTM carregats de: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_LSTM\\Amazon_Stock_Price_output\\Amazon_Stock_Price_output_best_weights.weights.h5\n",
      "  → LSTM Test MAE=4.5752, RMSE=5.7316, R²=0.9283\n",
      "  ✓ Mètriques LSTM guardades a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRID\\Amazon_Stock_Price_output\\Amazon_Stock_Price_output_metrics_LSTM_test.csv\n",
      "  ✓ XGBoost entrenat sobre residuals (train+val) per a Amazon_Stock_Price_output\n",
      "  → HÍBRID Test MAE=4.5288, RMSE=5.7489, R²=0.9279\n",
      "  ✓ Mètriques híbrides guardades a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRID\\Amazon_Stock_Price_output\\Amazon_Stock_Price_output_metrics_hybrid_test.csv\n",
      "  ✓ Gràfica Test HÍBRID guardada a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRID\\Amazon_Stock_Price_output\\Amazon_Stock_Price_output_test_plot_hybrid.html\n",
      "  ✓ Prediccions futures híbrides guardades a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRID\\Amazon_Stock_Price_output\\Amazon_Stock_Price_output_future_10days_hybrid.csv\n",
      "  ✓ Gràfica futura híbrida guardada a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRID\\Amazon_Stock_Price_output\\Amazon_Stock_Price_output_future_plot_hybrid.html\n",
      "\n",
      "===== Procesant: Euro_Stoxx_50_Stock_Price_output =====\n",
      "  ✓ Paràmetres LSTM carregats: layers=1, units=256, dropout=0.5, lr=0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning:\n",
      "\n",
      "Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 12 variables. \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Pesos LSTM carregats de: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_LSTM\\Euro_Stoxx_50_Stock_Price_output\\Euro_Stoxx_50_Stock_Price_output_best_weights.weights.h5\n",
      "  → LSTM Test MAE=51.0807, RMSE=64.9371, R²=0.7725\n",
      "  ✓ Mètriques LSTM guardades a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRID\\Euro_Stoxx_50_Stock_Price_output\\Euro_Stoxx_50_Stock_Price_output_metrics_LSTM_test.csv\n",
      "  ✓ XGBoost entrenat sobre residuals (train+val) per a Euro_Stoxx_50_Stock_Price_output\n",
      "  → HÍBRID Test MAE=45.9459, RMSE=57.8606, R²=0.8194\n",
      "  ✓ Mètriques híbrides guardades a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRID\\Euro_Stoxx_50_Stock_Price_output\\Euro_Stoxx_50_Stock_Price_output_metrics_hybrid_test.csv\n",
      "  ✓ Gràfica Test HÍBRID guardada a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRID\\Euro_Stoxx_50_Stock_Price_output\\Euro_Stoxx_50_Stock_Price_output_test_plot_hybrid.html\n",
      "  ✓ Prediccions futures híbrides guardades a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRID\\Euro_Stoxx_50_Stock_Price_output\\Euro_Stoxx_50_Stock_Price_output_future_10days_hybrid.csv\n",
      "  ✓ Gràfica futura híbrida guardada a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRID\\Euro_Stoxx_50_Stock_Price_output\\Euro_Stoxx_50_Stock_Price_output_future_plot_hybrid.html\n",
      "\n",
      "===== Procesant: Google_Stock_Price_output =====\n",
      "  ✓ Paràmetres LSTM carregats: layers=1, units=512, dropout=0.5, lr=0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning:\n",
      "\n",
      "Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 12 variables. \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Pesos LSTM carregats de: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_LSTM\\Google_Stock_Price_output\\Google_Stock_Price_output_best_weights.weights.h5\n",
      "  → LSTM Test MAE=3.3198, RMSE=4.3153, R²=0.9061\n",
      "  ✓ Mètriques LSTM guardades a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRID\\Google_Stock_Price_output\\Google_Stock_Price_output_metrics_LSTM_test.csv\n",
      "  ✓ XGBoost entrenat sobre residuals (train+val) per a Google_Stock_Price_output\n",
      "  → HÍBRID Test MAE=3.3204, RMSE=4.3075, R²=0.9065\n",
      "  ✓ Mètriques híbrides guardades a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRID\\Google_Stock_Price_output\\Google_Stock_Price_output_metrics_hybrid_test.csv\n",
      "  ✓ Gràfica Test HÍBRID guardada a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRID\\Google_Stock_Price_output\\Google_Stock_Price_output_test_plot_hybrid.html\n",
      "  ✓ Prediccions futures híbrides guardades a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRID\\Google_Stock_Price_output\\Google_Stock_Price_output_future_10days_hybrid.csv\n",
      "  ✓ Gràfica futura híbrida guardada a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRID\\Google_Stock_Price_output\\Google_Stock_Price_output_future_plot_hybrid.html\n",
      "\n",
      "===== Procesant: Hang_Seng_Stock_Price_output =====\n",
      "  ✓ Paràmetres LSTM carregats: layers=1, units=256, dropout=0.1, lr=0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning:\n",
      "\n",
      "Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 12 variables. \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Pesos LSTM carregats de: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_LSTM\\Hang_Seng_Stock_Price_output\\Hang_Seng_Stock_Price_output_best_weights.weights.h5\n",
      "  → LSTM Test MAE=348.2261, RMSE=482.8292, R²=0.8913\n",
      "  ✓ Mètriques LSTM guardades a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRID\\Hang_Seng_Stock_Price_output\\Hang_Seng_Stock_Price_output_metrics_LSTM_test.csv\n",
      "  ✓ XGBoost entrenat sobre residuals (train+val) per a Hang_Seng_Stock_Price_output\n",
      "  → HÍBRID Test MAE=313.5256, RMSE=443.1860, R²=0.9085\n",
      "  ✓ Mètriques híbrides guardades a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRID\\Hang_Seng_Stock_Price_output\\Hang_Seng_Stock_Price_output_metrics_hybrid_test.csv\n",
      "  ✓ Gràfica Test HÍBRID guardada a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRID\\Hang_Seng_Stock_Price_output\\Hang_Seng_Stock_Price_output_test_plot_hybrid.html\n",
      "  ✓ Prediccions futures híbrides guardades a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRID\\Hang_Seng_Stock_Price_output\\Hang_Seng_Stock_Price_output_future_10days_hybrid.csv\n",
      "  ✓ Gràfica futura híbrida guardada a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRID\\Hang_Seng_Stock_Price_output\\Hang_Seng_Stock_Price_output_future_plot_hybrid.html\n",
      "\n",
      "===== Procesant: IBEX_35_Stock_Price_output =====\n",
      "  ✓ Paràmetres LSTM carregats: layers=1, units=512, dropout=0.5, lr=0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning:\n",
      "\n",
      "Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 12 variables. \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Pesos LSTM carregats de: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_LSTM\\IBEX_35_Stock_Price_output\\IBEX_35_Stock_Price_output_best_weights.weights.h5\n",
      "  → LSTM Test MAE=112.6018, RMSE=139.6789, R²=0.8666\n",
      "  ✓ Mètriques LSTM guardades a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRID\\IBEX_35_Stock_Price_output\\IBEX_35_Stock_Price_output_metrics_LSTM_test.csv\n",
      "  ✓ XGBoost entrenat sobre residuals (train+val) per a IBEX_35_Stock_Price_output\n",
      "  → HÍBRID Test MAE=120.9788, RMSE=147.3662, R²=0.8516\n",
      "  ✓ Mètriques híbrides guardades a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRID\\IBEX_35_Stock_Price_output\\IBEX_35_Stock_Price_output_metrics_hybrid_test.csv\n",
      "  ✓ Gràfica Test HÍBRID guardada a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRID\\IBEX_35_Stock_Price_output\\IBEX_35_Stock_Price_output_test_plot_hybrid.html\n",
      "  ✓ Prediccions futures híbrides guardades a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRID\\IBEX_35_Stock_Price_output\\IBEX_35_Stock_Price_output_future_10days_hybrid.csv\n",
      "  ✓ Gràfica futura híbrida guardada a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRID\\IBEX_35_Stock_Price_output\\IBEX_35_Stock_Price_output_future_plot_hybrid.html\n",
      "\n",
      "===== Procesant: Indra_Stock_Price_output =====\n",
      "  ✓ Paràmetres LSTM carregats: layers=1, units=512, dropout=0.5, lr=0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning:\n",
      "\n",
      "Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 12 variables. \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Pesos LSTM carregats de: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_LSTM\\Indra_Stock_Price_output\\Indra_Stock_Price_output_best_weights.weights.h5\n",
      "  → LSTM Test MAE=234.5538, RMSE=313.4665, R²=0.7487\n",
      "  ✓ Mètriques LSTM guardades a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRID\\Indra_Stock_Price_output\\Indra_Stock_Price_output_metrics_LSTM_test.csv\n",
      "  ✓ XGBoost entrenat sobre residuals (train+val) per a Indra_Stock_Price_output\n",
      "  → HÍBRID Test MAE=473.6909, RMSE=539.1290, R²=0.2565\n",
      "  ✓ Mètriques híbrides guardades a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRID\\Indra_Stock_Price_output\\Indra_Stock_Price_output_metrics_hybrid_test.csv\n",
      "  ✓ Gràfica Test HÍBRID guardada a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRID\\Indra_Stock_Price_output\\Indra_Stock_Price_output_test_plot_hybrid.html\n",
      "  ✓ Prediccions futures híbrides guardades a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRID\\Indra_Stock_Price_output\\Indra_Stock_Price_output_future_10days_hybrid.csv\n",
      "  ✓ Gràfica futura híbrida guardada a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRID\\Indra_Stock_Price_output\\Indra_Stock_Price_output_future_plot_hybrid.html\n",
      "\n",
      "===== Procesant: P&G_Stock_Price_output =====\n",
      "  ✓ Paràmetres LSTM carregats: layers=1, units=256, dropout=0.3, lr=0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning:\n",
      "\n",
      "Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 12 variables. \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Pesos LSTM carregats de: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_LSTM\\P&G_Stock_Price_output\\P&G_Stock_Price_output_best_weights.weights.h5\n",
      "  → LSTM Test MAE=2.1416, RMSE=2.6764, R²=0.6456\n",
      "  ✓ Mètriques LSTM guardades a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRID\\P&G_Stock_Price_output\\P&G_Stock_Price_output_metrics_LSTM_test.csv\n",
      "  ✓ XGBoost entrenat sobre residuals (train+val) per a P&G_Stock_Price_output\n",
      "  → HÍBRID Test MAE=3.0134, RMSE=3.5953, R²=0.3604\n",
      "  ✓ Mètriques híbrides guardades a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRID\\P&G_Stock_Price_output\\P&G_Stock_Price_output_metrics_hybrid_test.csv\n",
      "  ✓ Gràfica Test HÍBRID guardada a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRID\\P&G_Stock_Price_output\\P&G_Stock_Price_output_test_plot_hybrid.html\n",
      "  ✓ Prediccions futures híbrides guardades a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRID\\P&G_Stock_Price_output\\P&G_Stock_Price_output_future_10days_hybrid.csv\n",
      "  ✓ Gràfica futura híbrida guardada a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRID\\P&G_Stock_Price_output\\P&G_Stock_Price_output_future_plot_hybrid.html\n",
      "\n",
      "===== Procesant: S&P500_Stock_Price_output =====\n",
      "  ✓ Paràmetres LSTM carregats: layers=2, units=128, dropout=0.1, lr=0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning:\n",
      "\n",
      "Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 18 variables. \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Pesos LSTM carregats de: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_LSTM\\S&P500_Stock_Price_output\\S&P500_Stock_Price_output_best_weights.weights.h5\n",
      "  → LSTM Test MAE=71.1080, RMSE=90.2894, R²=0.8303\n",
      "  ✓ Mètriques LSTM guardades a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRID\\S&P500_Stock_Price_output\\S&P500_Stock_Price_output_metrics_LSTM_test.csv\n",
      "  ✓ XGBoost entrenat sobre residuals (train+val) per a S&P500_Stock_Price_output\n",
      "  → HÍBRID Test MAE=99.7193, RMSE=116.6878, R²=0.7165\n",
      "  ✓ Mètriques híbrides guardades a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRID\\S&P500_Stock_Price_output\\S&P500_Stock_Price_output_metrics_hybrid_test.csv\n",
      "  ✓ Gràfica Test HÍBRID guardada a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRID\\S&P500_Stock_Price_output\\S&P500_Stock_Price_output_test_plot_hybrid.html\n",
      "  ✓ Prediccions futures híbrides guardades a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRID\\S&P500_Stock_Price_output\\S&P500_Stock_Price_output_future_10days_hybrid.csv\n",
      "  ✓ Gràfica futura híbrida guardada a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRID\\S&P500_Stock_Price_output\\S&P500_Stock_Price_output_future_plot_hybrid.html\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "# AFEGIM IMPORTS PER XGBOOST\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "# CONFIGURACIÓ DE RUTES\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "\n",
    "# Carpeta on estan els datasets CSV\n",
    "BASE_PATH = r\"C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\Conjunt de dades Preprocessades\\Datasets\"\n",
    "\n",
    "# Carpeta base on estan les subcarpetes amb pesos i paràmetres (per carregar el model LSTM)\n",
    "WEIGHTS_PATH_BASE = r\"C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_LSTM\"\n",
    "\n",
    "# Carpeta on desitgem guardar tots els resultats (metrics, gràfics, futures prediccions)\n",
    "RESULTS_PATH = r\"C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRID\"\n",
    "\n",
    "# Llista de fitxers CSV a processar\n",
    "DATASETS = [\n",
    "    \"Amazon_Stock_Price_output.csv\",\n",
    "    \"Euro_Stoxx_50_Stock_Price_output.csv\",\n",
    "    \"Google_Stock_Price_output.csv\",\n",
    "    \"Hang_Seng_Stock_Price_output.csv\",\n",
    "    \"IBEX_35_Stock_Price_output.csv\",\n",
    "    \"Indra_Stock_Price_output.csv\",\n",
    "    \"P&G_Stock_Price_output.csv\",\n",
    "    \"S&P500_Stock_Price_output.csv\"\n",
    "]\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "# HIPERPARÀMETRES I PARAMETRES\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "\n",
    "N_STEPS = 30\n",
    "FEATURE_COLUMNS = [\n",
    "    \"Open\",\"High\",\"Low\",\"Volume\",\n",
    "    \"EMA_7\",\"EMA_40\",\"MACD\",\"Signal_Line\",\n",
    "    \"MACD_Hist\",\"RSI\",\"ATR\"\n",
    "]\n",
    "TARGET_COLUMN = \"Close\"\n",
    "TEST_RATIO = 0.10\n",
    "VAL_RATIO  = 0.10\n",
    "TRAIN_RATIO = 1 - TEST_RATIO - VAL_RATIO\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "# FUNCIONS AUXILIARS\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "\n",
    "def create_sequences(X, y, n_steps=30):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(n_steps, len(X)):\n",
    "        Xs.append(X[i - n_steps:i])\n",
    "        ys.append(y[i])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "def build_lstm_model(sequence_length, n_features, units, n_layers, dropout, learning_rate):\n",
    "    model = Sequential()\n",
    "    for i in range(n_layers):\n",
    "        is_first = (i == 0)\n",
    "        is_last = (i == n_layers - 1)\n",
    "        return_sequences = not is_last\n",
    "        if is_first:\n",
    "            model.add(LSTM(\n",
    "                units, return_sequences=return_sequences,\n",
    "                input_shape=(sequence_length, n_features)\n",
    "            ))\n",
    "        else:\n",
    "            model.add(LSTM(units, return_sequences=return_sequences))\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, activation=\"linear\"))\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss=\"huber\", optimizer=optimizer, metrics=[\"mean_absolute_error\"])\n",
    "    return model\n",
    "\n",
    "def compute_metrics(model, X_scaled, y_scaled, scaler_y):\n",
    "    y_pred_scaled = model.predict(X_scaled, verbose=0)\n",
    "    y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
    "    y_true = scaler_y.inverse_transform(y_scaled)\n",
    "\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return mae, rmse, r2, y_true, y_pred\n",
    "\n",
    "def recompute_indicators(df):\n",
    "    close = df['Close']\n",
    "    df['EMA_7'] = close.ewm(span=7, adjust=False).mean()\n",
    "    df['EMA_40'] = close.ewm(span=40, adjust=False).mean()\n",
    "\n",
    "    ema_12 = close.ewm(span=12, adjust=False).mean()\n",
    "    ema_26 = close.ewm(span=26, adjust=False).mean()\n",
    "    macd = ema_12 - ema_26\n",
    "    signal = macd.ewm(span=9, adjust=False).mean()\n",
    "    df['MACD'] = macd\n",
    "    df['Signal_Line'] = signal\n",
    "    df['MACD_Hist'] = macd - signal\n",
    "\n",
    "    delta = close.diff()\n",
    "    gain = delta.clip(lower=0)\n",
    "    loss = -delta.clip(upper=0)\n",
    "    avg_gain = gain.ewm(alpha=1/14, adjust=False).mean()\n",
    "    avg_loss = loss.ewm(alpha=1/14, adjust=False).mean()\n",
    "    rs = avg_gain / (avg_loss + 1e-8)\n",
    "    df['RSI'] = 100 - (100 / (1 + rs))\n",
    "\n",
    "    df['ATR'] = (df['High'] - df['Low']).rolling(window=14).mean()\n",
    "\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "# BUCLE PRINCIPAL: CÀRREGA, LSTM, XGBOOST HÍBRID I GRAFICS\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "\n",
    "for filename in DATASETS:\n",
    "    dataset_name = os.path.splitext(filename)[0]\n",
    "    print(f\"\\n===== Procesant: {dataset_name} =====\")\n",
    "\n",
    "    # ───────────────────────────────────────────────────────────\n",
    "    # 1) DEFINICIÓ DE RUTES DE PESOS I PARÀMETRES LSTM\n",
    "    # ───────────────────────────────────────────────────────────\n",
    "    weights_folder = os.path.join(WEIGHTS_PATH_BASE, dataset_name)\n",
    "    weights_path   = os.path.join(weights_folder, f\"{dataset_name}_best_weights.weights.h5\")\n",
    "    params_path    = os.path.join(weights_folder, f\"{dataset_name}_best_params.json\")\n",
    "\n",
    "    # ───────────────────────────────────────────────────────────\n",
    "    # 2) DEFINICIÓ DE LA CARPETA DE RESULTATS\n",
    "    # ───────────────────────────────────────────────────────────\n",
    "    results_folder = os.path.join(RESULTS_PATH, dataset_name)\n",
    "    os.makedirs(results_folder, exist_ok=True)\n",
    "\n",
    "    if not os.path.isfile(weights_path) or not os.path.isfile(params_path):\n",
    "        print(f\"  ⚠️  Falten pesos o paràmetres per a {dataset_name}, s’omet.\")\n",
    "        continue\n",
    "\n",
    "    # ───────────────────────────────────────────────────────────\n",
    "    # 3) LLEGIR CSV ORIGINAL\n",
    "    # ───────────────────────────────────────────────────────────\n",
    "    data_path = os.path.join(BASE_PATH, filename)\n",
    "    df = pd.read_csv(data_path)\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df.sort_values(\"Date\", inplace=True)\n",
    "    df = df.dropna(subset=FEATURE_COLUMNS + [TARGET_COLUMN]).reset_index(drop=True)\n",
    "\n",
    "    # ───────────────────────────────────────────────────────────\n",
    "    # 4) CREAR SEQÜÈNCIES AMB LES DADES BRUTES (per a XGBoost)\n",
    "    # ───────────────────────────────────────────────────────────\n",
    "    data_X_raw = df[FEATURE_COLUMNS].values      # dades sense escalar\n",
    "    data_y_raw = df[TARGET_COLUMN].values.reshape(-1, 1)\n",
    "    X_seq_raw, y_seq_raw = create_sequences(data_X_raw, data_y_raw, n_steps=N_STEPS)\n",
    "\n",
    "    # ───────────────────────────────────────────────────────────\n",
    "    # 5) CREAR SEQÜÈNCIES PER A LSTM I DIVIDIR EN TRAIN/VAL/TEST\n",
    "    # ───────────────────────────────────────────────────────────\n",
    "    data_X = data_X_raw.copy()\n",
    "    data_y = data_y_raw.copy()\n",
    "    X_seq, y_seq = create_sequences(data_X, data_y, n_steps=N_STEPS)\n",
    "\n",
    "    n_total = len(X_seq)\n",
    "    train_end = int(n_total * TRAIN_RATIO)\n",
    "    val_end   = train_end + int(n_total * VAL_RATIO)\n",
    "\n",
    "    # Seqüències per a LSTM\n",
    "    X_train = X_seq[:train_end]\n",
    "    y_train = y_seq[:train_end]\n",
    "    X_val   = X_seq[train_end:val_end]\n",
    "    y_val   = y_seq[train_end:val_end]\n",
    "    X_test  = X_seq[val_end:]\n",
    "    y_test  = y_seq[val_end:]\n",
    "\n",
    "    # Seqüències brutes (raw) per a features XGBoost (només el darrer pas de cada seqüència)\n",
    "    X_seq_raw_train = X_seq_raw[:train_end]\n",
    "    X_seq_raw_val   = X_seq_raw[train_end:val_end]\n",
    "    X_seq_raw_test  = X_seq_raw[val_end:]\n",
    "\n",
    "    # ───────────────────────────────────────────────────────────\n",
    "    # 6) ESCALAT DE CARACTERÍSTIQUES (LSTM)\n",
    "    # ───────────────────────────────────────────────────────────\n",
    "    scaler_X = MinMaxScaler()\n",
    "    X_train_val_flat = X_seq[:val_end].reshape(-1, len(FEATURE_COLUMNS))\n",
    "    scaler_X.fit(X_train_val_flat)\n",
    "\n",
    "    scaler_y = MinMaxScaler()\n",
    "    scaler_y.fit(y_seq[:val_end])\n",
    "\n",
    "    def scale_X(X):\n",
    "        flat = X.reshape(-1, len(FEATURE_COLUMNS))\n",
    "        flat_scaled = scaler_X.transform(flat)\n",
    "        return flat_scaled.reshape(X.shape)\n",
    "\n",
    "    X_train_scaled = scale_X(X_train)\n",
    "    X_val_scaled   = scale_X(X_val)\n",
    "    X_test_scaled  = scale_X(X_test)\n",
    "\n",
    "    y_train_scaled = scaler_y.transform(y_train)\n",
    "    y_val_scaled   = scaler_y.transform(y_val)\n",
    "    y_test_scaled  = scaler_y.transform(y_test)\n",
    "\n",
    "    # ───────────────────────────────────────────────────────────\n",
    "    # 7) CARREGAR HIPERPARÀMETRES LSTM\n",
    "    # ───────────────────────────────────────────────────────────\n",
    "    with open(params_path, 'r') as f:\n",
    "        best_params = json.load(f)\n",
    "    n_layers      = best_params['n_layers']\n",
    "    units         = best_params['units']\n",
    "    dropout       = best_params['dropout']\n",
    "    learning_rate = best_params['learning_rate']\n",
    "\n",
    "    print(f\"  ✓ Paràmetres LSTM carregats: layers={n_layers}, units={units}, dropout={dropout}, lr={learning_rate}\")\n",
    "\n",
    "    # ───────────────────────────────────────────────────────────\n",
    "    # 8) RECONSTRUIR MODEL LSTM I CARREGAR PESOS\n",
    "    # ───────────────────────────────────────────────────────────\n",
    "    model = build_lstm_model(\n",
    "        sequence_length=N_STEPS,\n",
    "        n_features=len(FEATURE_COLUMNS),\n",
    "        units=units,\n",
    "        n_layers=n_layers,\n",
    "        dropout=dropout,\n",
    "        learning_rate=learning_rate\n",
    "    )\n",
    "    model.load_weights(weights_path)\n",
    "    print(f\"  ✓ Pesos LSTM carregats de: {weights_path}\")\n",
    "\n",
    "    # ───────────────────────────────────────────────────────────\n",
    "    # 9) AVALUAR LSTM SOBRE TEST\n",
    "    # ───────────────────────────────────────────────────────────\n",
    "    mae_test, rmse_test, r2_test, y_true_test, y_pred_test = compute_metrics(\n",
    "        model, X_test_scaled, y_test_scaled, scaler_y\n",
    "    )\n",
    "    print(f\"  → LSTM Test MAE={mae_test:.4f}, RMSE={rmse_test:.4f}, R²={r2_test:.4f}\")\n",
    "\n",
    "    # 9.1) Guardar mètriques LSTM\n",
    "    df_metrics = pd.DataFrame({\n",
    "        \"Dataset\": [dataset_name],\n",
    "        \"MAE_LSTM\": [mae_test],\n",
    "        \"RMSE_LSTM\": [rmse_test],\n",
    "        \"R2_LSTM\": [r2_test]\n",
    "    })\n",
    "    metrics_csv = os.path.join(results_folder, f\"{dataset_name}_metrics_LSTM_test.csv\")\n",
    "    df_metrics.to_csv(metrics_csv, index=False)\n",
    "    print(f\"  ✓ Mètriques LSTM guardades a: {metrics_csv}\")\n",
    "\n",
    "    # ───────────────────────────────────────────────────────────\n",
    "    # 10) XGB-HÍBRID: ENTRENAR XGBOOST SOBRE ELS RESIDUALS DE LA LSTM\n",
    "    # ───────────────────────────────────────────────────────────\n",
    "\n",
    "    # 10.1) Prediccions LSTM sobre train+val per calcular residuals\n",
    "    X_train_val_scaled = np.concatenate([X_train_scaled, X_val_scaled], axis=0)\n",
    "    y_train_val_scaled = np.concatenate([y_train_scaled, y_val_scaled], axis=0)\n",
    "\n",
    "    y_train_val_pred_scaled = model.predict(X_train_val_scaled, verbose=0)\n",
    "    y_train_val_pred_real = scaler_y.inverse_transform(y_train_val_pred_scaled)\n",
    "    y_train_val_real = scaler_y.inverse_transform(y_train_val_scaled)\n",
    "\n",
    "    residuals_train_val = (y_train_val_real.flatten() - y_train_val_pred_real.flatten())\n",
    "\n",
    "    # 10.2) Crear features per a XGBoost: darrer pas de seqüència raw + predicció LSTM\n",
    "    X_seq_raw_train_val = np.concatenate([X_seq_raw_train, X_seq_raw_val], axis=0)\n",
    "    X_last_train_val = X_seq_raw_train_val[:, -1, :]  # forma: (n_samples, n_features)\n",
    "\n",
    "    XGB_features_train_val = np.concatenate([\n",
    "        X_last_train_val,\n",
    "        y_train_val_pred_real.reshape(-1, 1)\n",
    "    ], axis=1)  # (n_samples, n_features+1)\n",
    "\n",
    "    # 10.3) Entrenar XGBoost regressor sobre els residuals\n",
    "    X_xgb_train, X_xgb_val, y_xgb_train, y_xgb_val = train_test_split(\n",
    "        XGB_features_train_val, residuals_train_val, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    xgb_model = xgb.XGBRegressor(\n",
    "        n_estimators=1000,\n",
    "        learning_rate=0.01,\n",
    "        max_depth=5,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42\n",
    "    )\n",
    "    xgb_model.fit(\n",
    "        X_xgb_train, y_xgb_train,\n",
    "        eval_set=[(X_xgb_val, y_xgb_val)],\n",
    "        verbose=False\n",
    "    )\n",
    "    print(f\"  ✓ XGBoost entrenat sobre residuals (train+val) per a {dataset_name}\")\n",
    "\n",
    "    # ───────────────────────────────────────────────────────────\n",
    "    # 11) AVALUAR HÍBRID SOBRE TEST\n",
    "    # ───────────────────────────────────────────────────────────\n",
    "\n",
    "    # 11.1) Obtenir prediccions LSTM sobre Test (invertides)\n",
    "    y_pred_lstm_test = y_pred_test.flatten()\n",
    "\n",
    "    # 11.2) Preparar features XGBoost per test: darrer pas seqüència raw + pred LSTM\n",
    "    X_last_test = X_seq_raw_test[:, -1, :]  # (n_test, n_features)\n",
    "    XGB_features_test = np.concatenate([\n",
    "        X_last_test,\n",
    "        y_pred_lstm_test.reshape(-1, 1)\n",
    "    ], axis=1)\n",
    "\n",
    "    # 11.3) Predir residuals amb XGBoost\n",
    "    residuals_pred_test = xgb_model.predict(XGB_features_test)\n",
    "\n",
    "    # 11.4) Predicció híbrida final = pred LSTM + pred residual\n",
    "    y_pred_hybrid_test = y_pred_lstm_test + residuals_pred_test\n",
    "\n",
    "    # 11.5) Calcular mètriques híbrides sobre Test\n",
    "    y_true_hybrid_test = y_true_test.flatten()\n",
    "    mae_hybrid = mean_absolute_error(y_true_hybrid_test, y_pred_hybrid_test)\n",
    "    rmse_hybrid = np.sqrt(mean_squared_error(y_true_hybrid_test, y_pred_hybrid_test))\n",
    "    r2_hybrid = r2_score(y_true_hybrid_test, y_pred_hybrid_test)\n",
    "    print(f\"  → HÍBRID Test MAE={mae_hybrid:.4f}, RMSE={rmse_hybrid:.4f}, R²={r2_hybrid:.4f}\")\n",
    "\n",
    "    # 11.6) Guardar mètriques híbrides\n",
    "    df_metrics_hybrid = pd.DataFrame({\n",
    "        \"Dataset\": [dataset_name],\n",
    "        \"MAE_HYBRID\": [mae_hybrid],\n",
    "        \"RMSE_HYBRID\": [rmse_hybrid],\n",
    "        \"R2_HYBRID\": [r2_hybrid]\n",
    "    })\n",
    "    metrics_hybrid_csv = os.path.join(results_folder, f\"{dataset_name}_metrics_hybrid_test.csv\")\n",
    "    df_metrics_hybrid.to_csv(metrics_hybrid_csv, index=False)\n",
    "    print(f\"  ✓ Mètriques híbrides guardades a: {metrics_hybrid_csv}\")\n",
    "\n",
    "    # ───────────────────────────────────────────────────────────\n",
    "    # 12) GRAFICA LSTM vs HÍBRID (Test)\n",
    "    # ───────────────────────────────────────────────────────────\n",
    "    start_test_idx = N_STEPS + val_end\n",
    "    dates_test = df['Date'].iloc[start_test_idx : start_test_idx + len(y_true_test)].reset_index(drop=True)\n",
    "\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=dates_test,\n",
    "        y=y_true_test.flatten(),\n",
    "        mode='lines',\n",
    "        name='Real (Close)',\n",
    "        line=dict(color='blue')\n",
    "    ))\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=dates_test,\n",
    "        y=y_pred_test.flatten(),\n",
    "        mode='lines',\n",
    "        name='Pred LSTM',\n",
    "        line=dict(color='red', dash='dash')\n",
    "    ))\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=dates_test,\n",
    "        y=y_pred_hybrid_test,\n",
    "        mode='lines',\n",
    "        name='Pred HÍBRIDA',\n",
    "        line=dict(color='orange', dash='dot')\n",
    "    ))\n",
    "    fig.update_layout(\n",
    "        title=f\"{dataset_name} – Real vs Prediccions (LSTM i HÍBRIDA) (Test)\",\n",
    "        xaxis_title='Data',\n",
    "        yaxis_title='Preu Close (USD)',\n",
    "        template='plotly_white',\n",
    "        xaxis_rangeslider_visible=True\n",
    "    )\n",
    "    plot_hybrid_html = os.path.join(results_folder, f\"{dataset_name}_test_plot_hybrid.html\")\n",
    "    fig.write_html(plot_hybrid_html)\n",
    "    print(f\"  ✓ Gràfica Test HÍBRID guardada a: {plot_hybrid_html}\")\n",
    "\n",
    "    # ───────────────────────────────────────────────────────────\n",
    "    # 13) PREDICCIÓ AUTOREGRESSIVA FUTURS 10 DIES AMB HÍBRID\n",
    "    # ───────────────────────────────────────────────────────────\n",
    "    df_future = df.copy().reset_index(drop=True)\n",
    "    recompute_indicators(df_future)\n",
    "\n",
    "    last_sequence = X_test_scaled[-1].copy().reshape(1, N_STEPS, len(FEATURE_COLUMNS))\n",
    "    future_preds_lstm = []\n",
    "    future_preds_hybrid = []\n",
    "    future_dates = pd.bdate_range(start=df_future['Date'].iloc[-1] + pd.Timedelta(days=1), periods=10)\n",
    "\n",
    "    for date in future_dates:\n",
    "        # 13.1) Pred LSTM -> real\n",
    "        y_pred_scaled = model.predict(last_sequence, verbose=0)[0][0]\n",
    "        y_pred_real = scaler_y.inverse_transform([[y_pred_scaled]])[0][0]\n",
    "        future_preds_lstm.append(y_pred_real)\n",
    "\n",
    "        # 13.2) Afegeix nova fila per a recompute_indicators\n",
    "        prev = df_future.iloc[-1]\n",
    "        new_row = {\n",
    "            'Date':        date,\n",
    "            'Open':        prev['Close'],\n",
    "            'High':        y_pred_real,\n",
    "            'Low':         y_pred_real,\n",
    "            'Volume':      prev['Volume'],\n",
    "            'Close':       y_pred_real,\n",
    "            'EMA_7':       np.nan,\n",
    "            'EMA_40':      np.nan,\n",
    "            'MACD':        np.nan,\n",
    "            'Signal_Line': np.nan,\n",
    "            'MACD_Hist':   np.nan,\n",
    "            'RSI':         np.nan,\n",
    "            'ATR':         np.nan\n",
    "        }\n",
    "        df_future.loc[len(df_future)] = new_row\n",
    "        recompute_indicators(df_future)\n",
    "\n",
    "        # 13.3) Construir nova seqüència per LSTM\n",
    "        recent_features = df_future[FEATURE_COLUMNS].iloc[-N_STEPS:].values\n",
    "        recent_scaled = scaler_X.transform(recent_features)\n",
    "        last_sequence = recent_scaled.reshape(1, N_STEPS, len(FEATURE_COLUMNS))\n",
    "\n",
    "        # 13.4) Predicció HÍBRIDA:\n",
    "        X_last_future = df_future[FEATURE_COLUMNS].iloc[-1].values.reshape(1, -1)  # shape (1, n_features)\n",
    "        Xgb_feat = np.concatenate([X_last_future, np.array([[y_pred_real]])], axis=1)\n",
    "        residual_xgb = xgb_model.predict(Xgb_feat)[0]\n",
    "        y_pred_hybrid = y_pred_real + residual_xgb\n",
    "        future_preds_hybrid.append(y_pred_hybrid)\n",
    "\n",
    "        # 13.5) Actualitzar 'Close' per al següent pas\n",
    "        df_future.at[df_future.index[-1], 'Close'] = y_pred_hybrid\n",
    "\n",
    "    # ───────────────────────────────────────────────────────────\n",
    "    # 14) GUARDAR PREDICCIONS FUTURES HÍBRIDES I LSTM EN CSV\n",
    "    # ───────────────────────────────────────────────────────────\n",
    "    df_fut_pred = pd.DataFrame({\n",
    "        \"Date\": future_dates,\n",
    "        \"Pred_Close_LSTM\": future_preds_lstm,\n",
    "        \"Pred_Close_HYBRID\": future_preds_hybrid\n",
    "    })\n",
    "    fut_csv = os.path.join(results_folder, f\"{dataset_name}_future_10days_hybrid.csv\")\n",
    "    df_fut_pred.to_csv(fut_csv, index=False)\n",
    "    print(f\"  ✓ Prediccions futures híbrides guardades a: {fut_csv}\")\n",
    "\n",
    "    # ───────────────────────────────────────────────────────────\n",
    "    # 15) GRAFICAR HISTÒRIC + PREDICCIONS FUTURES HÍBRIDES\n",
    "    # ───────────────────────────────────────────────────────────\n",
    "    fig_future = go.Figure()\n",
    "    fig_future.add_trace(go.Scatter(\n",
    "        x=df['Date'], y=df['Close'],\n",
    "        mode='lines', name='Històric Close', line=dict(color='lightblue')\n",
    "    ))\n",
    "    fig_future.add_trace(go.Scatter(\n",
    "        x=future_dates, y=np.array(future_preds_hybrid),\n",
    "        mode='lines+markers', name='Predicció futura HÍBRIDA',\n",
    "        line=dict(color='orange', dash='dash'),\n",
    "        marker=dict(size=6)\n",
    "    ))\n",
    "    fig_future.update_layout(\n",
    "        title=f\"{dataset_name} – Predicció HÍBRIDA Pròxims 10 Dies\",\n",
    "        xaxis_title='Data',\n",
    "        yaxis_title='Preu Close (USD)',\n",
    "        template='plotly_white',\n",
    "        xaxis_rangeslider_visible=True\n",
    "    )\n",
    "    fut_hybrid_html = os.path.join(results_folder, f\"{dataset_name}_future_plot_hybrid.html\")\n",
    "    fig_future.write_html(fut_hybrid_html)\n",
    "    print(f\"  ✓ Gràfica futura híbrida guardada a: {fut_hybrid_html}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2b8f3c",
   "metadata": {},
   "source": [
    "Model híbrid correcte - canvis realitzats en l'estructura del codi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4afca23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Amazon_Stock_Price_output...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning:\n",
      "\n",
      "Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 12 variables. \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM Test → MAE: 3.6188, RMSE: 4.6093, R2: 0.9534\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Hybrid Test → MAE: 3.2784, RMSE: 4.2841, R2: 0.9597\n",
      "  ✓ Gràfica Test HÍBRID guardada a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRIDS\\Amazon_Stock_Price_output\\Amazon_Stock_Price_output_test_plot_hybrid.html\n",
      "  ✓ Prediccions futures híbrides guardades a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRIDS\\Amazon_Stock_Price_output\\Amazon_Stock_Price_output_future_10days_hybrid.csv\n",
      "  ✓ Gràfica futura híbrida guardada a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRIDS\\Amazon_Stock_Price_output\\Amazon_Stock_Price_output_future_plot_hybrid.html\n",
      "Processing Euro_Stoxx_50_Stock_Price_output...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning:\n",
      "\n",
      "Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 12 variables. \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM Test → MAE: 68.0060, RMSE: 85.1416, R2: 0.5995\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Hybrid Test → MAE: 25.9500, RMSE: 32.4365, R2: 0.9419\n",
      "  ✓ Gràfica Test HÍBRID guardada a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRIDS\\Euro_Stoxx_50_Stock_Price_output\\Euro_Stoxx_50_Stock_Price_output_test_plot_hybrid.html\n",
      "  ✓ Prediccions futures híbrides guardades a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRIDS\\Euro_Stoxx_50_Stock_Price_output\\Euro_Stoxx_50_Stock_Price_output_future_10days_hybrid.csv\n",
      "  ✓ Gràfica futura híbrida guardada a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRIDS\\Euro_Stoxx_50_Stock_Price_output\\Euro_Stoxx_50_Stock_Price_output_future_plot_hybrid.html\n",
      "Processing Google_Stock_Price_output...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning:\n",
      "\n",
      "Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 12 variables. \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM Test → MAE: 4.3533, RMSE: 5.4124, R2: 0.8543\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "Hybrid Test → MAE: 2.2546, RMSE: 2.8637, R2: 0.9592\n",
      "  ✓ Gràfica Test HÍBRID guardada a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRIDS\\Google_Stock_Price_output\\Google_Stock_Price_output_test_plot_hybrid.html\n",
      "  ✓ Prediccions futures híbrides guardades a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRIDS\\Google_Stock_Price_output\\Google_Stock_Price_output_future_10days_hybrid.csv\n",
      "  ✓ Gràfica futura híbrida guardada a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRIDS\\Google_Stock_Price_output\\Google_Stock_Price_output_future_plot_hybrid.html\n",
      "Processing Hang_Seng_Stock_Price_output...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning:\n",
      "\n",
      "Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 12 variables. \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM Test → MAE: 341.6728, RMSE: 490.8676, R2: 0.8854\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Hybrid Test → MAE: 207.8854, RMSE: 312.8780, R2: 0.9535\n",
      "  ✓ Gràfica Test HÍBRID guardada a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRIDS\\Hang_Seng_Stock_Price_output\\Hang_Seng_Stock_Price_output_test_plot_hybrid.html\n",
      "  ✓ Prediccions futures híbrides guardades a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRIDS\\Hang_Seng_Stock_Price_output\\Hang_Seng_Stock_Price_output_future_10days_hybrid.csv\n",
      "  ✓ Gràfica futura híbrida guardada a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRIDS\\Hang_Seng_Stock_Price_output\\Hang_Seng_Stock_Price_output_future_plot_hybrid.html\n",
      "Processing IBEX_35_Stock_Price_output...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning:\n",
      "\n",
      "Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 12 variables. \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM Test → MAE: 168.0230, RMSE: 208.7942, R2: 0.6668\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "Hybrid Test → MAE: 79.8749, RMSE: 96.5863, R2: 0.9287\n",
      "  ✓ Gràfica Test HÍBRID guardada a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRIDS\\IBEX_35_Stock_Price_output\\IBEX_35_Stock_Price_output_test_plot_hybrid.html\n",
      "  ✓ Prediccions futures híbrides guardades a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRIDS\\IBEX_35_Stock_Price_output\\IBEX_35_Stock_Price_output_future_10days_hybrid.csv\n",
      "  ✓ Gràfica futura híbrida guardada a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRIDS\\IBEX_35_Stock_Price_output\\IBEX_35_Stock_Price_output_future_plot_hybrid.html\n",
      "Processing Indra_Stock_Price_output...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning:\n",
      "\n",
      "Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 12 variables. \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM Test → MAE: 233.7392, RMSE: 295.7193, R2: 0.7778\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Hybrid Test → MAE: 171.6424, RMSE: 226.0883, R2: 0.8701\n",
      "  ✓ Gràfica Test HÍBRID guardada a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRIDS\\Indra_Stock_Price_output\\Indra_Stock_Price_output_test_plot_hybrid.html\n",
      "  ✓ Prediccions futures híbrides guardades a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRIDS\\Indra_Stock_Price_output\\Indra_Stock_Price_output_future_10days_hybrid.csv\n",
      "  ✓ Gràfica futura híbrida guardada a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRIDS\\Indra_Stock_Price_output\\Indra_Stock_Price_output_future_plot_hybrid.html\n",
      "Processing P&G_Stock_Price_output...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning:\n",
      "\n",
      "Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 12 variables. \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM Test → MAE: 1.8727, RMSE: 2.3827, R2: 0.7218\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Hybrid Test → MAE: 1.1756, RMSE: 1.5143, R2: 0.8876\n",
      "  ✓ Gràfica Test HÍBRID guardada a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRIDS\\P&G_Stock_Price_output\\P&G_Stock_Price_output_test_plot_hybrid.html\n",
      "  ✓ Prediccions futures híbrides guardades a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRIDS\\P&G_Stock_Price_output\\P&G_Stock_Price_output_future_10days_hybrid.csv\n",
      "  ✓ Gràfica futura híbrida guardada a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRIDS\\P&G_Stock_Price_output\\P&G_Stock_Price_output_future_plot_hybrid.html\n",
      "Processing S&P500_Stock_Price_output...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning:\n",
      "\n",
      "Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 18 variables. \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM Test → MAE: 81.7329, RMSE: 101.3684, R2: 0.7772\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Hybrid Test → MAE: 73.3193, RMSE: 86.9410, R2: 0.8361\n",
      "  ✓ Gràfica Test HÍBRID guardada a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRIDS\\S&P500_Stock_Price_output\\S&P500_Stock_Price_output_test_plot_hybrid.html\n",
      "  ✓ Prediccions futures híbrides guardades a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRIDS\\S&P500_Stock_Price_output\\S&P500_Stock_Price_output_future_10days_hybrid.csv\n",
      "  ✓ Gràfica futura híbrida guardada a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\LSTM\\RESULTATS_HIBRIDS\\S&P500_Stock_Price_output\\S&P500_Stock_Price_output_future_plot_hybrid.html\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
    "import xgboost as xgb\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "# CONFIGURATION\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "BASE_DIR = r\"C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\"\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"Conjunt de dades Preprocessades\", \"Datasets\")\n",
    "LSTM_WEIGHTS_DIR = os.path.join(BASE_DIR, \"LSTM\", \"RESULTATS_LSTM\")\n",
    "OUTPUT_DIR = os.path.join(BASE_DIR, \"LSTM\", \"RESULTATS_HIBRIDS\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "DATASETS = [\n",
    "    \"Amazon_Stock_Price_output.csv\",\n",
    "    \"Euro_Stoxx_50_Stock_Price_output.csv\",\n",
    "    \"Google_Stock_Price_output.csv\",\n",
    "    \"Hang_Seng_Stock_Price_output.csv\",\n",
    "    \"IBEX_35_Stock_Price_output.csv\",\n",
    "    \"Indra_Stock_Price_output.csv\",\n",
    "    \"P&G_Stock_Price_output.csv\",\n",
    "    \"S&P500_Stock_Price_output.csv\",\n",
    "]\n",
    "\n",
    "# Hyperparameters\n",
    "N_STEPS = 30\n",
    "FEATURE_COLUMNS = [\n",
    "    \"Open\", \"High\", \"Low\", \"Volume\",\n",
    "    \"EMA_7\", \"EMA_40\", \"MACD\", \"Signal_Line\",\n",
    "    \"MACD_Hist\", \"RSI\", \"ATR\"\n",
    "]\n",
    "TARGET_COLUMN = \"Close\"\n",
    "TEST_RATIO = 0.10\n",
    "VAL_RATIO = 0.10\n",
    "TRAIN_RATIO = 1 - TEST_RATIO - VAL_RATIO\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "# FUNCTIONS\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "\n",
    "def load_dataset(path):\n",
    "    df = pd.read_csv(path, parse_dates=[\"Date\"]).sort_values(\"Date\")\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "def compute_technical_indicators(df):\n",
    "    close = df[TARGET_COLUMN]\n",
    "    df[\"EMA_7\"] = close.ewm(span=7, adjust=False).mean()\n",
    "    df[\"EMA_40\"] = close.ewm(span=40, adjust=False).mean()\n",
    "    ema12 = close.ewm(span=12, adjust=False).mean()\n",
    "    ema26 = close.ewm(span=26, adjust=False).mean()\n",
    "    macd = ema12 - ema26\n",
    "    signal = macd.ewm(span=9, adjust=False).mean()\n",
    "    df[\"MACD\"] = macd\n",
    "    df[\"Signal_Line\"] = signal\n",
    "    df[\"MACD_Hist\"] = macd - signal\n",
    "    delta = close.diff()\n",
    "    gain = delta.clip(lower=0)\n",
    "    loss = -delta.clip(upper=0)\n",
    "    avg_gain = gain.ewm(alpha=1/14, adjust=False).mean()\n",
    "    avg_loss = loss.ewm(alpha=1/14, adjust=False).mean()\n",
    "    rs = avg_gain / (avg_loss + 1e-8)\n",
    "    df[\"RSI\"] = 100 - (100 / (1 + rs))\n",
    "    df[\"ATR\"] = (df[\"High\"] - df[\"Low\"]).rolling(window=14).mean()\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_sequences(data, n_steps=N_STEPS):\n",
    "    X, y = [], []\n",
    "    for i in range(n_steps, len(data)):\n",
    "        X.append(data[i-n_steps:i, :-1])\n",
    "        y.append(data[i, -1])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "def build_and_compile_lstm(input_shape, params):\n",
    "    model = Sequential()\n",
    "    for i in range(params['n_layers']):\n",
    "        return_seq = i < params['n_layers'] - 1\n",
    "        layer_args = dict(units=params['units'], return_sequences=return_seq)\n",
    "        if i == 0:\n",
    "            model.add(LSTM(**layer_args, input_shape=input_shape))\n",
    "        else:\n",
    "            model.add(LSTM(**layer_args))\n",
    "        model.add(Dropout(params['dropout']))\n",
    "    model.add(Dense(1, activation=\"linear\"))\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=params['learning_rate'])\n",
    "    model.compile(loss=\"huber\", optimizer=optimizer, metrics=[\"mae\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_model(model, X, y, scaler):\n",
    "    y_pred = model.predict(X, verbose=0)\n",
    "    y_true = scaler.inverse_transform(y.reshape(-1, 1)).flatten()\n",
    "    y_pred_real = scaler.inverse_transform(y_pred).flatten()\n",
    "    return {\n",
    "        'MAE': mean_absolute_error(y_true, y_pred_real),\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_true, y_pred_real)),\n",
    "        'R2': r2_score(y_true, y_pred_real),\n",
    "        'y_true': y_true,\n",
    "        'y_pred': y_pred_real\n",
    "    }\n",
    "\n",
    "\n",
    "def train_xgb_on_residuals(X_feats, residuals):\n",
    "    np.random.seed(42)\n",
    "    idx = np.arange(len(X_feats))\n",
    "    np.random.shuffle(idx)\n",
    "    split = int(len(idx) * 0.8)\n",
    "    train_idx, val_idx = idx[:split], idx[split:]\n",
    "\n",
    "    X_train_xgb = X_feats[train_idx]\n",
    "    y_train_xgb = residuals[train_idx]\n",
    "    X_val_xgb = X_feats[val_idx]\n",
    "    y_val_xgb = residuals[val_idx]\n",
    "\n",
    "    xgb_reg = xgb.XGBRegressor(\n",
    "        n_estimators=1000,\n",
    "        learning_rate=0.01,\n",
    "        max_depth=5,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42\n",
    "    )\n",
    "    xgb_reg.fit(\n",
    "        X_train_xgb, y_train_xgb,\n",
    "        eval_set=[(X_val_xgb, y_val_xgb)],\n",
    "        verbose=False\n",
    "    )\n",
    "    return xgb_reg\n",
    "\n",
    "\n",
    "def plot_results(dates, true_vals, lstm_preds, hybrid_preds, title, output_path):\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=dates, y=true_vals, mode='lines', name='Real'))\n",
    "    fig.add_trace(go.Scatter(x=dates, y=lstm_preds, mode='lines', name='LSTM Prediction'))\n",
    "    fig.add_trace(go.Scatter(x=dates, y=hybrid_preds, mode='lines', name='Hybrid Prediction'))\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis_title='Date', yaxis_title='Close Price',\n",
    "        template='plotly_dark', xaxis_rangeslider_visible=True\n",
    "    )\n",
    "    fig.write_html(output_path)\n",
    "\n",
    "\n",
    "def main():\n",
    "    for file in DATASETS:\n",
    "        dataset_name = os.path.splitext(file)[0]\n",
    "        print(f\"Processing {dataset_name}...\")\n",
    "\n",
    "        # Create a subdirectory for this dataset's outputs\n",
    "        dataset_output_dir = os.path.join(OUTPUT_DIR, dataset_name)\n",
    "        os.makedirs(dataset_output_dir, exist_ok=True)\n",
    "\n",
    "        # Load and preprocess\n",
    "        df = load_dataset(os.path.join(DATA_DIR, file))\n",
    "        df = compute_technical_indicators(df).dropna().reset_index(drop=True)\n",
    "\n",
    "        # Prepare sequences and splits\n",
    "        arr = df[FEATURE_COLUMNS + [TARGET_COLUMN]].values\n",
    "        X_all, y_all = create_sequences(arr)\n",
    "        n_samples = len(X_all)\n",
    "        train_end = int(n_samples * TRAIN_RATIO)\n",
    "        val_end = train_end + int(n_samples * VAL_RATIO)\n",
    "\n",
    "        X_train, y_train = X_all[:train_end], y_all[:train_end]\n",
    "        X_val, y_val = X_all[train_end:val_end], y_all[train_end:val_end]\n",
    "        X_test, y_test = X_all[val_end:], y_all[val_end:]\n",
    "\n",
    "        # Scaling\n",
    "        scaler_X = MinMaxScaler().fit(X_all.reshape(-1, X_all.shape[-1]))\n",
    "        scaler_y = MinMaxScaler().fit(y_all.reshape(-1, 1))\n",
    "        X_train_scaled = scaler_X.transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
    "        X_val_scaled = scaler_X.transform(X_val.reshape(-1, X_val.shape[-1])).reshape(X_val.shape)\n",
    "        X_test_scaled = scaler_X.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(X_test.shape)\n",
    "        y_train_scaled = scaler_y.transform(y_train.reshape(-1, 1))\n",
    "        y_val_scaled = scaler_y.transform(y_val.reshape(-1, 1))\n",
    "        y_test_scaled = scaler_y.transform(y_test.reshape(-1, 1))\n",
    "\n",
    "        # Load LSTM\n",
    "        param_file = os.path.join(LSTM_WEIGHTS_DIR, dataset_name, f\"{dataset_name}_best_params.json\")\n",
    "        weights_file = os.path.join(LSTM_WEIGHTS_DIR, dataset_name, f\"{dataset_name}_best_weights.weights.h5\")\n",
    "        with open(param_file) as pf:\n",
    "            params = json.load(pf)\n",
    "        lstm = build_and_compile_lstm((N_STEPS, len(FEATURE_COLUMNS)), params)\n",
    "        lstm.load_weights(weights_file)\n",
    "\n",
    "        # Evaluate LSTM on test\n",
    "        lstm_metrics = evaluate_model(lstm, X_test_scaled, y_test_scaled, scaler_y)\n",
    "        print(f\"LSTM Test → MAE: {lstm_metrics['MAE']:.4f}, RMSE: {lstm_metrics['RMSE']:.4f}, R2: {lstm_metrics['R2']:.4f}\")\n",
    "\n",
    "        # Hybrid training on residuals\n",
    "        train_val_scaled = np.concatenate([X_train_scaled, X_val_scaled])\n",
    "        y_train_val_scaled = np.concatenate([y_train_scaled, y_val_scaled])\n",
    "        y_pred_train_val = lstm.predict(train_val_scaled)\n",
    "        true_train_val = scaler_y.inverse_transform(y_train_val_scaled).flatten()\n",
    "        pred_train_val = scaler_y.inverse_transform(y_pred_train_val).flatten()\n",
    "        residuals = true_train_val - pred_train_val\n",
    "\n",
    "        raw_arr = df[FEATURE_COLUMNS].values[N_STEPS:]\n",
    "        xgb_feats = np.hstack([raw_arr[:len(residuals)], pred_train_val.reshape(-1, 1)])\n",
    "        xgb_model = train_xgb_on_residuals(xgb_feats, residuals)\n",
    "\n",
    "        # Test hybrid\n",
    "        lstm_test_pred = scaler_y.inverse_transform(lstm.predict(X_test_scaled)).flatten()\n",
    "        raw_test = df[FEATURE_COLUMNS].values[N_STEPS + val_end:]\n",
    "        xgb_test_feats = np.hstack([raw_test, lstm_test_pred.reshape(-1, 1)])\n",
    "        hybrid_preds = lstm_test_pred + xgb_model.predict(xgb_test_feats)\n",
    "        true_test = df[TARGET_COLUMN].values[N_STEPS + val_end:]\n",
    "\n",
    "        mae_h = mean_absolute_error(true_test, hybrid_preds)\n",
    "        rmse_h = np.sqrt(mean_squared_error(true_test, hybrid_preds))\n",
    "        r2_h = r2_score(true_test, hybrid_preds)\n",
    "        print(f\"Hybrid Test → MAE: {mae_h:.4f}, RMSE: {rmse_h:.4f}, R2: {r2_h:.4f}\")\n",
    "\n",
    "        # Save metrics CSV\n",
    "        metrics_df = pd.DataFrame([{\n",
    "            **{'Dataset': dataset_name},\n",
    "            **{f\"{k}_LSTM\": v for k, v in lstm_metrics.items() if k in ['MAE','RMSE','R2']},\n",
    "            **{'MAE_HYBRID': mae_h, 'RMSE_HYBRID': rmse_h, 'R2_HYBRID': r2_h}\n",
    "        }])\n",
    "        metrics_df.to_csv(os.path.join(dataset_output_dir, f\"{dataset_name}_metrics.csv\"), index=False)\n",
    "\n",
    "        # Plot and save hybrid test comparison\n",
    "        start_test_idx = N_STEPS + val_end\n",
    "        dates_test = df['Date'].iloc[start_test_idx:start_test_idx + len(true_test)].reset_index(drop=True)\n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Scatter(x=dates_test, y=true_test, mode='lines', name='Real (Close)'))\n",
    "        fig.add_trace(go.Scatter(x=dates_test, y=lstm_test_pred, mode='lines', name='Pred LSTM', line=dict(dash='dash')))\n",
    "        fig.add_trace(go.Scatter(x=dates_test, y=hybrid_preds, mode='lines', name='Pred HÍBRIDA', line=dict(dash='dot')))\n",
    "        fig.update_layout(\n",
    "            title=f\"{dataset_name} – Real vs Prediccions (Test, LSTM i HÍBRIDA)\",\n",
    "            xaxis_title='Data', yaxis_title='Preu (Close)',\n",
    "            template='plotly_white', xaxis_rangeslider_visible=True\n",
    "        )\n",
    "        hybrid_html = os.path.join(dataset_output_dir, f\"{dataset_name}_test_plot_hybrid.html\")\n",
    "        fig.write_html(hybrid_html)\n",
    "        print(f\"  ✓ Gràfica Test HÍBRID guardada a: {hybrid_html}\")\n",
    "\n",
    "        # Future 10-day autoregressive hybrid prediction\n",
    "        df_future = df.copy().reset_index(drop=True)\n",
    "        recompute_indicators(df_future)\n",
    "\n",
    "        last_sequence = X_test_scaled[-1].copy().reshape(1, N_STEPS, len(FEATURE_COLUMNS))\n",
    "        future_preds_lstm = []\n",
    "        future_preds_hybrid = []\n",
    "        future_dates = pd.bdate_range(start=df_future['Date'].iloc[-1] + pd.Timedelta(days=1), periods=10)\n",
    "\n",
    "        for date in future_dates:\n",
    "            # 13.1) Pred LSTM -> real\n",
    "            y_pred_scaled = lstm.predict(last_sequence, verbose=0)[0][0]\n",
    "            y_pred_real = scaler_y.inverse_transform([[y_pred_scaled]])[0][0]\n",
    "            future_preds_lstm.append(y_pred_real)\n",
    "\n",
    "            # 13.2) Afegeix nova fila per a recompute_indicators\n",
    "            prev = df_future.iloc[-1]\n",
    "            new_row = {\n",
    "                'Date':        date,\n",
    "                'Open':        prev['Close'],\n",
    "                'High':        y_pred_real,\n",
    "                'Low':         y_pred_real,\n",
    "                'Volume':      prev['Volume'],\n",
    "                'Close':       y_pred_real,\n",
    "                'EMA_7':       np.nan,\n",
    "                'EMA_40':      np.nan,\n",
    "                'MACD':        np.nan,\n",
    "                'Signal_Line': np.nan,\n",
    "                'MACD_Hist':   np.nan,\n",
    "                'RSI':         np.nan,\n",
    "                'ATR':         np.nan\n",
    "            }\n",
    "            df_future.loc[len(df_future)] = new_row\n",
    "            recompute_indicators(df_future)\n",
    "\n",
    "            # 13.3) Construir nova seqüència per LSTM\n",
    "            recent_features = df_future[FEATURE_COLUMNS].iloc[-N_STEPS:].values\n",
    "            recent_scaled = scaler_X.transform(recent_features)\n",
    "            last_sequence = recent_scaled.reshape(1, N_STEPS, len(FEATURE_COLUMNS))\n",
    "\n",
    "            # 13.4) Predicció HÍBRIDA:\n",
    "            X_last_future = df_future[FEATURE_COLUMNS].iloc[-1].values.reshape(1, -1)  # shape (1, n_features)\n",
    "            Xgb_feat = np.concatenate([X_last_future, np.array([[y_pred_real]])], axis=1)\n",
    "            residual_xgb = xgb_model.predict(Xgb_feat)[0]\n",
    "            y_pred_hybrid = y_pred_real + residual_xgb\n",
    "            future_preds_hybrid.append(y_pred_hybrid)\n",
    "\n",
    "            # 13.5) Actualitzar 'Close' per al següent pas\n",
    "            df_future.at[df_future.index[-1], 'Close'] = y_pred_hybrid\n",
    "\n",
    "        # ───────────────────────────────────────────────────────────\n",
    "        # 14) GUARDAR PREDICCIONS FUTURES HÍBRIDES I LSTM EN CSV\n",
    "        # ───────────────────────────────────────────────────────────\n",
    "        df_fut_pred = pd.DataFrame({\n",
    "            \"Date\": future_dates,\n",
    "            \"Pred_Close_LSTM\": future_preds_lstm,\n",
    "            \"Pred_Close_HYBRID\": future_preds_hybrid\n",
    "        })\n",
    "        fut_csv = os.path.join(dataset_output_dir, f\"{dataset_name}_future_10days_hybrid.csv\")\n",
    "        df_fut_pred.to_csv(fut_csv, index=False)\n",
    "        print(f\"  ✓ Prediccions futures híbrides guardades a: {fut_csv}\")\n",
    "\n",
    "        # Plot and save historical + future hybrid\n",
    "        fig_fut = go.Figure()\n",
    "        fig_fut.add_trace(go.Scatter(x=df['Date'], y=df['Close'], mode='lines', name='Històric Close', line=dict(color='lightblue')))\n",
    "        fig_fut.add_trace(go.Scatter(x=future_dates, y=future_preds_hybrid, mode='lines+markers', name='Pred futura HÍBRIDA', line=dict(color='orange', dash='dash'), marker=dict(size=6)))\n",
    "        fig_fut.update_layout(\n",
    "            title=f\"{dataset_name} – Predicció Pròxims 10 Dies (HÍBRID: LSTM + XGBOOST)\",\n",
    "            xaxis_title='Data', yaxis_title='Preu (Close)', template='plotly_white', xaxis_rangeslider_visible=True\n",
    "        )\n",
    "        fut_html = os.path.join(dataset_output_dir, f\"{dataset_name}_future_plot_hybrid.html\")\n",
    "        fig_fut.write_html(fut_html)\n",
    "        print(f\"  ✓ Gràfica futura híbrida guardada a: {fut_html}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
