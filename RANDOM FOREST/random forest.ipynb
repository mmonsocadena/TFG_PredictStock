{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edf2728b",
   "metadata": {},
   "source": [
    "## MODEL RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e7f6b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error  # IMPORTA MAE\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88b4673c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mostres train original: 894\n",
      "Mostres train augmentat: 5364\n",
      "\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: FitFailedWarning:\n",
      "\n",
      "\n",
      "75 fits failed out of a total of 250.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "\n",
      "c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning:\n",
      "\n",
      "One or more of the test scores are non-finite: [-728.01835069 -194.4653834  -194.97506175 -236.75413356 -125.24962838\n",
      " -215.33121049           nan           nan -216.05519781 -162.14053589\n",
      "           nan -194.9858372            nan -216.3416792            nan\n",
      " -751.16669624 -236.9804217  -180.24216811 -215.9969904  -180.76408613\n",
      " -202.05427434 -750.03804493           nan           nan -193.58648447\n",
      "           nan -747.01085394 -253.77046898           nan           nan\n",
      " -201.84338191           nan -751.62743207 -178.73829372 -233.30669361\n",
      " -193.58648447           nan -194.9858372  -740.10948689 -748.16304084\n",
      " -145.09037752 -215.18998802           nan -113.12723574           nan\n",
      " -214.8390229  -127.42316786 -234.76068115 -215.18998802           nan]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Millors hiperparàmetres trobats (RandomizedSearchCV amb augmentació):\n",
      "  n_estimators: 300\n",
      "  min_samples_split: 5\n",
      "  min_samples_leaf: 1\n",
      "  max_features: sqrt\n",
      "  max_depth: 20\n",
      "\n",
      "Avaluació final sobre Test:\n",
      "  RMSE Test: 467763.6603\n",
      "  MAE  Test: 512.5705\n",
      "  R²   Test: -0.4566\n",
      "\n",
      "Top 10 features per importància:\n",
      "       feature  importance\n",
      "0          Low    0.216481\n",
      "1         High    0.207479\n",
      "2         Open    0.152913\n",
      "3        EMA_7    0.136083\n",
      "4   Close_lag1    0.093531\n",
      "5   Close_lag2    0.082658\n",
      "6   Close_lag3    0.046920\n",
      "7       EMA_40    0.032044\n",
      "8   Close_lag5    0.018680\n",
      "9  Close_lag10    0.004178\n",
      "\n",
      "Variables seleccionades (importància ≥ 0.01): 9 de 16\n",
      "\n",
      "Model reduït (pilotatge de features):\n",
      "  RMSE Test (reduït): 457607.1621\n",
      "  MAE  Test (reduït): 505.1915\n",
      "  R²   Test (reduït): -0.4250\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Carrega de dades ---\n",
    "BASE_PATH = r\"C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\Conjunt de dades Preprocessades\\Datasets\"\n",
    "file_name = \"S&P500_Stock_Price_output.csv\"\n",
    "file_path = os.path.join(BASE_PATH, file_name)\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# --- 2. Preprocessament inicial ---\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df = df.sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "# --- 3. Enginyeria de característiques (només lags de 'Close') ---\n",
    "for lag in [1, 2, 3, 5, 10]:\n",
    "    df[f'Close_lag{lag}'] = df['Close'].shift(lag)\n",
    "\n",
    "# --- 4. Definició de X i y ---\n",
    "target_col   = \"Close\"\n",
    "feature_cols = [c for c in df.columns if c not in ['Date', target_col]]\n",
    "X = df[feature_cols].copy()\n",
    "y = df[target_col].copy()\n",
    "\n",
    "# --- 5. Split temporal 70 % train_val / 30 % test ---\n",
    "split_index = int(len(df) * 0.7)\n",
    "X_train_val = X.iloc[:split_index].reset_index(drop=True)\n",
    "y_train_val = y.iloc[:split_index].reset_index(drop=True)\n",
    "X_test      = X.iloc[split_index:].reset_index(drop=True)\n",
    "y_test      = y.iloc[split_index:].reset_index(drop=True)\n",
    "\n",
    "# --- 6. Funció d'augmentació (jittering) ----------\n",
    "def augment_features(X_orig, y_orig, n_copies=3, noise_level=0.01, random_state=42):\n",
    "    \"\"\"\n",
    "    Crea còpies augmentades de X_orig i y_orig mitjançant jittering:\n",
    "    - Afegeix soroll gaussià a cada feature contínua (totes les columnes de X).\n",
    "    - Manté el target y sens canvis.\n",
    "    - Retorna X_concat i y_concat amb (1 + n_copies) blocs.\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    cont_cols = X_orig.columns.tolist()\n",
    "\n",
    "    X_list = [X_orig.copy()]\n",
    "    y_list = [y_orig.copy()]\n",
    "\n",
    "    for _ in range(n_copies):\n",
    "        X_aug = X_orig.copy()\n",
    "        stds = X_orig[cont_cols].std().values  # desviació de cada feature\n",
    "        noise = np.random.normal(loc=0.0, scale=1.0, size=X_orig[cont_cols].shape)\n",
    "        noise = noise * (noise_level * stds)  # escalar soroll per feature\n",
    "\n",
    "        X_aug.loc[:, cont_cols] = X_orig[cont_cols] + noise\n",
    "        X_list.append(X_aug)\n",
    "        y_list.append(y_orig.copy())\n",
    "\n",
    "    X_all = pd.concat(X_list, ignore_index=True)\n",
    "    y_all = pd.concat(y_list, ignore_index=True)\n",
    "    return X_all, y_all\n",
    "\n",
    "# Realitzem augmentació sobre el conjunt de train_val\n",
    "# Per exemple: 5 còpies amb 1% de soroll\n",
    "X_train_aug, y_train_aug = augment_features(\n",
    "    X_train_val,\n",
    "    y_train_val,\n",
    "    n_copies=5,\n",
    "    noise_level=0.01,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Mostres train original: {X_train_val.shape[0]}\")\n",
    "print(f\"Mostres train augmentat: {X_train_aug.shape[0]}\\n\")\n",
    "\n",
    "# --- 7. Hyperparameter tuning amb RandomizedSearchCV + TimeSeriesSplit sobre X_train_aug ---\n",
    "param_dist = {\n",
    "    'n_estimators':      [int(x) for x in np.linspace(100, 500, num=5)],  # 100,200,300,400,500\n",
    "    'max_depth':         [None, 5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf':  [1, 2, 4],\n",
    "    'max_features':      ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "rf   = RandomForestRegressor(random_state=42)\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,                # 50 iteracions aleatòries\n",
    "    cv=tscv,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_search.fit(X_train_aug, y_train_aug)\n",
    "best_params = random_search.best_params_\n",
    "\n",
    "print(\"Millors hiperparàmetres trobats (RandomizedSearchCV amb augmentació):\")\n",
    "for param, val in best_params.items():\n",
    "    print(f\"  {param}: {val}\")\n",
    "print()\n",
    "\n",
    "# --- 8. Entrenar model final sobre TOT train_val AUGMENTAT ---\n",
    "final_rf = RandomForestRegressor(**best_params, random_state=42)\n",
    "final_rf.fit(X_train_aug, y_train_aug)\n",
    "\n",
    "# --- 9. Avaluació sobre Test (sense augmentar el test) ---\n",
    "y_pred_test = final_rf.predict(X_test)\n",
    "rmse_test   = mean_squared_error(y_test, y_pred_test)  # RMSE\n",
    "mae_test    = mean_absolute_error(y_test, y_pred_test)               # MAE\n",
    "r2_test     = r2_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"Avaluació final sobre Test:\")\n",
    "print(f\"  RMSE Test: {rmse_test:.4f}\")\n",
    "print(f\"  MAE  Test: {mae_test:.4f}\")   # IMPRIMIM MAE\n",
    "print(f\"  R²   Test: {r2_test:.4f}\\n\")\n",
    "\n",
    "# --- 10. Selecció de variables per importància ---\n",
    "importances = final_rf.feature_importances_\n",
    "feat_imp = pd.DataFrame({\n",
    "    'feature':    X_train_val.columns,\n",
    "    'importance': importances\n",
    "}).sort_values('importance', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"Top 10 features per importància:\")\n",
    "print(feat_imp.head(10))\n",
    "\n",
    "# Exemple: eliminar les variables amb importància < llindar\n",
    "llindar      = 0.01\n",
    "features_sel = feat_imp[feat_imp['importance'] >= llindar]['feature'].tolist()\n",
    "\n",
    "print(f\"\\nVariables seleccionades (importància ≥ {llindar}): {len(features_sel)} de {len(feature_cols)}\\n\")\n",
    "\n",
    "X_train_val_red = X_train_val[features_sel]\n",
    "X_test_red      = X_test[features_sel]\n",
    "\n",
    "# Entrenem un model reduït (sense augmentar en aquest pas)\n",
    "final_rf_red = RandomForestRegressor(**best_params, random_state=42)\n",
    "final_rf_red.fit(X_train_val_red, y_train_val)\n",
    "y_pred_red = final_rf_red.predict(X_test_red)\n",
    "\n",
    "rmse_red = mean_squared_error(y_test, y_pred_red)  # RMSE reduït\n",
    "mae_red  = mean_absolute_error(y_test, y_pred_red)               # MAE reduït\n",
    "r2_red   = r2_score(y_test, y_pred_red)\n",
    "\n",
    "print(\"Model reduït (pilotatge de features):\")\n",
    "print(f\"  RMSE Test (reduït): {rmse_red:.4f}\")\n",
    "print(f\"  MAE  Test (reduït): {mae_red:.4f}\")   # IMPRIMIM MAE per al model reduït\n",
    "print(f\"  R²   Test (reduït): {r2_red:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "902c80f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Mètriques del model reduït guardades a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\RANDOM FOREST\\resultats_RANDOM_FOREST\\S&P500_Stock_Price_output\\S&P500_reduced_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "base_results_folder = r\"C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\RANDOM FOREST\\resultats_RANDOM_FOREST\"\n",
    "subfolder = \"S&P500_Stock_Price_output\"\n",
    "model_folder = os.path.join(base_results_folder, subfolder)\n",
    "dataset_name = \"S&P500\"\n",
    "# Ens assegurem que la carpeta existeixi\n",
    "os.makedirs(model_folder, exist_ok=True)\n",
    "\n",
    "# 14.2) Construir un DataFrame amb les mètriques\n",
    "metrics_red = pd.DataFrame({\n",
    "    \"Model\": [\"RandomForest_Reducit\"],\n",
    "    \"RMSE_test\": [rmse_red],\n",
    "    \"MAE_test\":  [mae_red],\n",
    "    \"R2_test\":   [r2_red]\n",
    "})\n",
    "\n",
    "# 14.3) Escriure el CSV amb les mètriques\n",
    "metrics_csv_path = os.path.join(model_folder, f\"{dataset_name}_reduced_metrics.csv\")\n",
    "metrics_red.to_csv(metrics_csv_path, index=False)\n",
    "\n",
    "print(f\"  ✓ Mètriques del model reduït guardades a: {metrics_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dbfa12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Gráfica Test (modelo reducido) guardada en: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\RANDOM FOREST\\resultats_RANDOM_FOREST\\Amazon_Stock_Price_output\\Amazon_test_reduced_plot.html\n",
      "⚠️  Detectado que features_sel incluye variables distintas a lags de 'Close'.\n",
      "    Reentrenando un nuevo RandomForestRegressor usando únicamente: ['Close_lag1', 'Close_lag2', 'Close_lag3', 'Close_lag5', 'Close_lag10']\n",
      "  ✓ Predicciones futuras (modelo reducido) guardadas en: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\RANDOM FOREST\\resultats_RANDOM_FOREST\\Amazon_Stock_Price_output\\Amazon_future_10days_reduced.csv\n",
      "  ✓ Gráfica futura (modelo reducido) guardada en: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\RANDOM FOREST\\resultats_RANDOM_FOREST\\Amazon_Stock_Price_output\\Amazon_future_reduced_plot.html\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# (Suposant que ja tens definides: df, split_index, X_train_val, y_train_val,\n",
    "#   final_rf_red, best_params, features_sel, y_test, y_pred_red, etc.)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 11) Graficar Real vs Predicho (Test) con el modelo reducido\n",
    "# --------------------------------------------------\n",
    "\n",
    "# 11.1) Recuperar las fechas de test a partir del DataFrame original:\n",
    "dates_test = df['Date'].iloc[split_index:].reset_index(drop=True)\n",
    "\n",
    "# 11.2) Construir las series \"real\" y \"predicho\" para graficar\n",
    "y_true_red = y_test.reset_index(drop=True)               # Valores reales (Close) del test\n",
    "y_pred_red  = pd.Series(y_pred_red).reset_index(drop=True)  # Predicciones del modelo reducido\n",
    "\n",
    "# 11.3) Plotly: Real vs Predicho\n",
    "fig_test = go.Figure()\n",
    "fig_test.add_trace(go.Scatter(\n",
    "    x=dates_test,\n",
    "    y=y_true_red,\n",
    "    mode='lines',\n",
    "    name='Real (Close)',\n",
    "    line=dict(color='blue')\n",
    "))\n",
    "fig_test.add_trace(go.Scatter(\n",
    "    x=dates_test,\n",
    "    y=y_pred_red,\n",
    "    mode='lines',\n",
    "    name='Predicho (RF reducido)',\n",
    "    line=dict(color='red', dash='dash')\n",
    "))\n",
    "fig_test.update_layout(\n",
    "    title=\"S&P500 – Real vs Predicho (Test) [Modelo Reducido]\",\n",
    "    xaxis_title='Fecha',\n",
    "    yaxis_title='Precio Close (USD)',\n",
    "    template='plotly_dark',\n",
    "    xaxis_rangeslider_visible=True\n",
    ")\n",
    "\n",
    "# Guardar la gráfica en HTML\n",
    "\n",
    "test_plot_path = os.path.join(model_folder, f\"{dataset_name}_test_reduced_plot.html\")\n",
    "fig_test.write_html(test_plot_path)\n",
    "print(f\"  ✓ Gráfica Test (modelo reducido) guardada en: {test_plot_path}\")\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 12) Preparación para Predicción autoregresiva de 10 días\n",
    "# --------------------------------------------------\n",
    "\n",
    "# 12.1) Seleccionar únicamente las columnas de lag en features_sel\n",
    "lag_features = [f for f in features_sel if f.startswith(\"Close_lag\")]\n",
    "\n",
    "if len(lag_features) == 0:\n",
    "    raise ValueError(\n",
    "        \"No hay columnas 'Close_lag' en features_sel. \"\n",
    "        \"El modelo reducido no usa ningún lag de 'Close', por lo que no es posible hacer predicción autoregresiva.\"\n",
    "    )\n",
    "\n",
    "# 12.2) Si features_sel incluía otras variables (por ejemplo 'Open', 'High', etc.),\n",
    "#        reentrenamos un modelo solo con lag_features para las predicciones futuras:\n",
    "if len(lag_features) < len(features_sel):\n",
    "    print(\"⚠️  Detectado que features_sel incluye variables distintas a lags de 'Close'.\")\n",
    "    print(\"    Reentrenando un nuevo RandomForestRegressor usando únicamente:\", lag_features)\n",
    "    final_rf_lag = RandomForestRegressor(**best_params, random_state=42)\n",
    "    final_rf_lag.fit(X_train_val[lag_features], y_train_val)\n",
    "    modelo_para_futuro = final_rf_lag\n",
    "else:\n",
    "    # Si ya solo había lags, usamos final_rf_red directamente:\n",
    "    modelo_para_futuro = final_rf_red\n",
    "\n",
    "# 12.3) Determinar el máximo lag (p.ej. Close_lag10 → max_lag = 10)\n",
    "max_lag = max(int(f.split(\"Close_lag\")[1]) for f in lag_features)\n",
    "\n",
    "# 12.4) Crear deque con los últimos 'max_lag' valores reales de df['Close']\n",
    "last_closes = deque(df['Close'].iloc[-max_lag:].values, maxlen=max_lag)\n",
    "\n",
    "# 12.5) Generar las próximas 10 fechas laborables\n",
    "future_dates = pd.bdate_range(\n",
    "    start=df['Date'].iloc[-1] + pd.Timedelta(days=1),\n",
    "    periods=10\n",
    ")\n",
    "\n",
    "future_preds = []\n",
    "\n",
    "# 12.6) Bucle día a día para predecir autoregresivamente\n",
    "for fecha in future_dates:\n",
    "    # 12.6.1) Construir un diccionario X_new con todas las lag_features\n",
    "    X_new = {}\n",
    "    for f in lag_features:\n",
    "        lag_num = int(f.split(\"Close_lag\")[1])\n",
    "        X_new[f] = last_closes[-lag_num]\n",
    "\n",
    "    # 12.6.2) Convertir a DataFrame de una sola fila\n",
    "    X_new_df = pd.DataFrame([X_new])\n",
    "\n",
    "    # 12.6.3) Predecir el próximo 'Close'\n",
    "    y_pred_fut = modelo_para_futuro.predict(X_new_df)[0]\n",
    "    future_preds.append(y_pred_fut)\n",
    "\n",
    "    # 12.6.4) Añadir la predicción a last_closes\n",
    "    last_closes.append(y_pred_fut)\n",
    "\n",
    "# 12.7) Guardar predicciones futuras en un CSV\n",
    "df_fut_pred = pd.DataFrame({\n",
    "    \"Date\": future_dates,\n",
    "    \"Predicted_Close\": future_preds\n",
    "})\n",
    "future_csv_path = os.path.join(model_folder, f\"{dataset_name}_future_10days_reduced.csv\")\n",
    "df_fut_pred.to_csv(future_csv_path, index=False)\n",
    "print(f\"  ✓ Predicciones futuras (modelo reducido) guardadas en: {future_csv_path}\")\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 13) Graficar histórico + predicciones futuras\n",
    "# --------------------------------------------------\n",
    "\n",
    "fig_future = go.Figure()\n",
    "# 13.1) Histórico real de 'Close'\n",
    "fig_future.add_trace(go.Scatter(\n",
    "    x=df['Date'],\n",
    "    y=df['Close'],\n",
    "    mode='lines',\n",
    "    name='Histórico Close',\n",
    "    line=dict(color='lightblue')\n",
    "))\n",
    "# 13.2) Serie de predicciones futuras\n",
    "fig_future.add_trace(go.Scatter(\n",
    "    x=future_dates,\n",
    "    y=np.array(future_preds),\n",
    "    mode='lines+markers',\n",
    "    name='Predicción futura (10 días)',\n",
    "    line=dict(color='orange', dash='dash'),\n",
    "    marker=dict(size=6)\n",
    "))\n",
    "fig_future.update_layout(\n",
    "    title=\"S&P500 – Predicción Próximos 10 Días (Modelo Reducido)\",\n",
    "    xaxis_title='Fecha',\n",
    "    yaxis_title='Precio Close (USD)',\n",
    "    template='plotly_dark',\n",
    "    xaxis_rangeslider_visible=True\n",
    ")\n",
    "\n",
    "future_plot_path = os.path.join(model_folder, f\"{dataset_name}_future_reduced_plot.html\")\n",
    "fig_future.write_html(future_plot_path)\n",
    "print(f\"  ✓ Gráfica futura (modelo reducido) guardada en: {future_plot_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
