{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edf2728b",
   "metadata": {},
   "source": [
    "## MODEL RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7f6b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error  # IMPORTA MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b4673c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mostres train original: 894\n",
      "Mostres train augmentat: 5364\n",
      "\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: FitFailedWarning:\n",
      "\n",
      "\n",
      "75 fits failed out of a total of 250.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "\n",
      "c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning:\n",
      "\n",
      "One or more of the test scores are non-finite: [-728.01835069 -194.4653834  -194.97506175 -236.75413356 -125.24962838\n",
      " -215.33121049           nan           nan -216.05519781 -162.14053589\n",
      "           nan -194.9858372            nan -216.3416792            nan\n",
      " -751.16669624 -236.9804217  -180.24216811 -215.9969904  -180.76408613\n",
      " -202.05427434 -750.03804493           nan           nan -193.58648447\n",
      "           nan -747.01085394 -253.77046898           nan           nan\n",
      " -201.84338191           nan -751.62743207 -178.73829372 -233.30669361\n",
      " -193.58648447           nan -194.9858372  -740.10948689 -748.16304084\n",
      " -145.09037752 -215.18998802           nan -113.12723574           nan\n",
      " -214.8390229  -127.42316786 -234.76068115 -215.18998802           nan]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Millors hiperparàmetres trobats (RandomizedSearchCV amb augmentació):\n",
      "  n_estimators: 300\n",
      "  min_samples_split: 5\n",
      "  min_samples_leaf: 1\n",
      "  max_features: sqrt\n",
      "  max_depth: 20\n",
      "\n",
      "Avaluació final sobre Test:\n",
      "  RMSE Test: 467763.6603\n",
      "  MAE  Test: 512.5705\n",
      "  R²   Test: -0.4566\n",
      "\n",
      "Top 10 features per importància:\n",
      "       feature  importance\n",
      "0          Low    0.216481\n",
      "1         High    0.207479\n",
      "2         Open    0.152913\n",
      "3        EMA_7    0.136083\n",
      "4   Close_lag1    0.093531\n",
      "5   Close_lag2    0.082658\n",
      "6   Close_lag3    0.046920\n",
      "7       EMA_40    0.032044\n",
      "8   Close_lag5    0.018680\n",
      "9  Close_lag10    0.004178\n",
      "\n",
      "Variables seleccionades (importància ≥ 0.01): 9 de 16\n",
      "\n",
      "Model reduït (pilotatge de features):\n",
      "  RMSE Test (reduït): 457607.1621\n",
      "  MAE  Test (reduït): 505.1915\n",
      "  R²   Test (reduït): -0.4250\n"
     ]
    }
   ],
   "source": [
    "# Carrega de dades \n",
    "BASE_PATH = r\"C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\Conjunt de dades Preprocessades\\Datasets\"\n",
    "file_name = \"S&P500_Stock_Price_output.csv\"\n",
    "file_path = os.path.join(BASE_PATH, file_name)\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Preprocessament inicial \n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df = df.sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "# Enginyeria de característiques (només lags de 'Close')\n",
    "for lag in [1, 2, 3, 5, 10]:\n",
    "    df[f'Close_lag{lag}'] = df['Close'].shift(lag)\n",
    "\n",
    "# Definició de X i y \n",
    "target_col   = \"Close\"\n",
    "feature_cols = [c for c in df.columns if c not in ['Date', target_col]]\n",
    "X = df[feature_cols].copy()\n",
    "y = df[target_col].copy()\n",
    "\n",
    "# Split temporal 70 % train_val / 30 % test\n",
    "split_index = int(len(df) * 0.7)\n",
    "X_train_val = X.iloc[:split_index].reset_index(drop=True)\n",
    "y_train_val = y.iloc[:split_index].reset_index(drop=True)\n",
    "X_test      = X.iloc[split_index:].reset_index(drop=True)\n",
    "y_test      = y.iloc[split_index:].reset_index(drop=True)\n",
    "\n",
    "# Funció d'augmentació (jittering) \n",
    "def augment_features(X_orig, y_orig, n_copies=3, noise_level=0.01, random_state=42):\n",
    " \n",
    "    np.random.seed(random_state)\n",
    "    cont_cols = X_orig.columns.tolist()\n",
    "\n",
    "    X_list = [X_orig.copy()]\n",
    "    y_list = [y_orig.copy()]\n",
    "\n",
    "    for _ in range(n_copies):\n",
    "        X_aug = X_orig.copy()\n",
    "        stds = X_orig[cont_cols].std().values  # desviació de cada feature\n",
    "        noise = np.random.normal(loc=0.0, scale=1.0, size=X_orig[cont_cols].shape)\n",
    "        noise = noise * (noise_level * stds)  # escalar soroll per feature\n",
    "\n",
    "        X_aug.loc[:, cont_cols] = X_orig[cont_cols] + noise\n",
    "        X_list.append(X_aug)\n",
    "        y_list.append(y_orig.copy())\n",
    "\n",
    "    X_all = pd.concat(X_list, ignore_index=True)\n",
    "    y_all = pd.concat(y_list, ignore_index=True)\n",
    "    return X_all, y_all\n",
    "\n",
    "# Realitzem augmentació sobre el conjunt de train_val\n",
    "X_train_aug, y_train_aug = augment_features(\n",
    "    X_train_val,\n",
    "    y_train_val,\n",
    "    n_copies=5,\n",
    "    noise_level=0.01,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Mostres train original: {X_train_val.shape[0]}\")\n",
    "print(f\"Mostres train augmentat: {X_train_aug.shape[0]}\\n\")\n",
    "\n",
    "# Hyperparameter tuning amb RandomizedSearchCV + TimeSeriesSplit sobre X_train_aug\n",
    "param_dist = {\n",
    "    'n_estimators':      [int(x) for x in np.linspace(100, 500, num=5)], \n",
    "    'max_depth':         [None, 5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf':  [1, 2, 4],\n",
    "    'max_features':      ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "rf   = RandomForestRegressor(random_state=42)\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,                # 50 iteracions aleatòries\n",
    "    cv=tscv,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_search.fit(X_train_aug, y_train_aug)\n",
    "best_params = random_search.best_params_\n",
    "\n",
    "print(\"Millors hiperparàmetres trobats (RandomizedSearchCV amb augmentació):\")\n",
    "for param, val in best_params.items():\n",
    "    print(f\"  {param}: {val}\")\n",
    "print()\n",
    "\n",
    "# Entrenar model final sobre TOT train_val AUGMENTAT \n",
    "final_rf = RandomForestRegressor(**best_params, random_state=42)\n",
    "final_rf.fit(X_train_aug, y_train_aug)\n",
    "\n",
    "# Avaluació sobre Test (sense augmentar el test) \n",
    "y_pred_test = final_rf.predict(X_test)\n",
    "rmse_test   = np.sqrt(mean_squared_error(y_test, y_pred_test))  \n",
    "mae_test    = mean_absolute_error(y_test, y_pred_test)            \n",
    "r2_test     = r2_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"Avaluació final sobre Test:\")\n",
    "print(f\"  RMSE Test: {rmse_test:.4f}\")\n",
    "print(f\"  MAE  Test: {mae_test:.4f}\")   \n",
    "print(f\"  R²   Test: {r2_test:.4f}\\n\")\n",
    "\n",
    "# Selecció de variables per importància\n",
    "importances = final_rf.feature_importances_\n",
    "feat_imp = pd.DataFrame({\n",
    "    'feature':    X_train_val.columns,\n",
    "    'importance': importances\n",
    "}).sort_values('importance', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"Top 10 features per importància:\")\n",
    "print(feat_imp.head(10))\n",
    "\n",
    "# Eliminar les variables amb importància < llindar\n",
    "llindar      = 0.01\n",
    "features_sel = feat_imp[feat_imp['importance'] >= llindar]['feature'].tolist()\n",
    "\n",
    "print(f\"\\nVariables seleccionades (importància ≥ {llindar}): {len(features_sel)} de {len(feature_cols)}\\n\")\n",
    "\n",
    "X_train_val_red = X_train_val[features_sel]\n",
    "X_test_red      = X_test[features_sel]\n",
    "\n",
    "# Entrenem un model reduït (sense augmentar en aquest pas)\n",
    "final_rf_red = RandomForestRegressor(**best_params, random_state=42)\n",
    "final_rf_red.fit(X_train_val_red, y_train_val)\n",
    "y_pred_red = final_rf_red.predict(X_test_red)\n",
    "\n",
    "rmse_red = np.sqrt(mean_squared_error(y_test, y_pred_red))  \n",
    "mae_red  = mean_absolute_error(y_test, y_pred_red)               \n",
    "r2_red   = r2_score(y_test, y_pred_red)\n",
    "\n",
    "# Mètriques mdoel reduït\n",
    "print(\"Model reduït (pilotatge de features):\")\n",
    "print(f\"  RMSE Test (reduït): {rmse_red:.4f}\")\n",
    "print(f\"  MAE  Test (reduït): {mae_red:.4f}\")   \n",
    "print(f\"  R²   Test (reduït): {r2_red:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902c80f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Mètriques del model reduït guardades a: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\RANDOM FOREST\\resultats_RANDOM_FOREST\\S&P500_Stock_Price_output\\S&P500_reduced_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "base_results_folder = r\"C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\RANDOM FOREST\\resultats_RANDOM_FOREST\"\n",
    "subfolder = \"S&P500_Stock_Price_output\"\n",
    "model_folder = os.path.join(base_results_folder, subfolder)\n",
    "dataset_name = \"S&P500\"\n",
    "# Ens assegurem que la carpeta existeixi\n",
    "os.makedirs(model_folder, exist_ok=True)\n",
    "\n",
    "# Construir un DataFrame amb les mètriques\n",
    "metrics_red = pd.DataFrame({\n",
    "    \"Model\": [\"RandomForest_Reducit\"],\n",
    "    \"RMSE_test\": [rmse_red],\n",
    "    \"MAE_test\":  [mae_red],\n",
    "    \"R2_test\":   [r2_red]\n",
    "})\n",
    "\n",
    "# Escriure el CSV amb les mètriques\n",
    "metrics_csv_path = os.path.join(model_folder, f\"{dataset_name}_reduced_metrics.csv\")\n",
    "metrics_red.to_csv(metrics_csv_path, index=False)\n",
    "\n",
    "print(f\"  ✓ Mètriques del model reduït guardades a: {metrics_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dbfa12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Gráfica Test (modelo reducido) guardada en: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\RANDOM FOREST\\resultats_RANDOM_FOREST\\Amazon_Stock_Price_output\\Amazon_test_reduced_plot.html\n",
      "⚠️  Detectado que features_sel incluye variables distintas a lags de 'Close'.\n",
      "    Reentrenando un nuevo RandomForestRegressor usando únicamente: ['Close_lag1', 'Close_lag2', 'Close_lag3', 'Close_lag5', 'Close_lag10']\n",
      "  ✓ Predicciones futuras (modelo reducido) guardadas en: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\RANDOM FOREST\\resultats_RANDOM_FOREST\\Amazon_Stock_Price_output\\Amazon_future_10days_reduced.csv\n",
      "  ✓ Gráfica futura (modelo reducido) guardada en: C:\\Users\\jesus\\Desktop\\TFG\\GitHUb\\TFG_PredictStock\\RANDOM FOREST\\resultats_RANDOM_FOREST\\Amazon_Stock_Price_output\\Amazon_future_reduced_plot.html\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Gràfica Real vs Predit (Test) amb el model reduït\n",
    "# Recuperar les dates de test a partir del DataFrame original:\n",
    "dates_test = df['Date'].iloc[split_index:].reset_index(drop=True)\n",
    "\n",
    "# Construir les sèries \"real\" i \"predit\" per graficar\n",
    "y_true_red = y_test.reset_index(drop=True)               \n",
    "y_pred_red  = pd.Series(y_pred_red).reset_index(drop=True)  \n",
    "\n",
    "# Plotly: Real vs Predit\n",
    "fig_test = go.Figure()\n",
    "fig_test.add_trace(go.Scatter(\n",
    "    x=dates_test,\n",
    "    y=y_true_red,\n",
    "    mode='lines',\n",
    "    name='Real (Close)',\n",
    "    line=dict(color='blue')\n",
    "))\n",
    "fig_test.add_trace(go.Scatter(\n",
    "    x=dates_test,\n",
    "    y=y_pred_red,\n",
    "    mode='lines',\n",
    "    name='Predit (RF reduït)',\n",
    "    line=dict(color='red', dash='dash')\n",
    "))\n",
    "fig_test.update_layout(\n",
    "    title=\"S&P500 – Real vs Predit (Test) [Model reduït]\",\n",
    "    xaxis_title='Data',\n",
    "    yaxis_title='Preu Close (USD)',\n",
    "    template='plotly_dark',\n",
    "    xaxis_rangeslider_visible=True\n",
    ")\n",
    "\n",
    "# Desar la gràfica en HTML\n",
    "test_plot_path = os.path.join(model_folder, f\"{dataset_name}_test_reduced_plot.html\")\n",
    "fig_test.write_html(test_plot_path)\n",
    "print(f\"  ✓ Gràfica Test (model reduït) desada a: {test_plot_path}\")\n",
    "\n",
    "\n",
    "# Preparació per a la predicció autoregressiva de 10 dies\n",
    "# Seleccionar només les columnes de lags a features_sel\n",
    "lag_features = [f for f in features_sel if f.startswith(\"Close_lag\")]\n",
    "\n",
    "if len(lag_features) == 0:\n",
    "    raise ValueError(\n",
    "        \"No hi ha columnes 'Close_lag' a features_sel. \"\n",
    "        \"El model reduït no fa servir cap lag de 'Close', per tant no és possible fer predicció autoregressiva.\"\n",
    "    )\n",
    "\n",
    "# Si features_sel incloïa altres variables (p. ex. 'Open', 'High', etc.),\n",
    "#        reentrenem un model només amb lag_features per les prediccions futures:\n",
    "if len(lag_features) < len(features_sel):\n",
    "    print(\"⚠️  S'ha detectat que features_sel inclou variables diferents de lags de 'Close'.\")\n",
    "    print(\"    Reentrenant un nou RandomForestRegressor només amb:\", lag_features)\n",
    "    final_rf_lag = RandomForestRegressor(**best_params, random_state=42)\n",
    "    final_rf_lag.fit(X_train_val[lag_features], y_train_val)\n",
    "    modelo_para_futuro = final_rf_lag\n",
    "else:\n",
    "    # Si només hi havia lags, fem servir final_rf_red directament:\n",
    "    modelo_para_futuro = final_rf_red\n",
    "\n",
    "# Determinar el màxim lag (p. ex. Close_lag10 → max_lag = 10)\n",
    "max_lag = max(int(f.split(\"Close_lag\")[1]) for f in lag_features)\n",
    "\n",
    "# Crear deque amb els últims 'max_lag' valors reals de df['Close']\n",
    "last_closes = deque(df['Close'].iloc[-max_lag:].values, maxlen=max_lag)\n",
    "\n",
    "# Generar els propers 10 dies laborables\n",
    "future_dates = pd.bdate_range(\n",
    "    start=df['Date'].iloc[-1] + pd.Timedelta(days=1),\n",
    "    periods=10\n",
    ")\n",
    "\n",
    "future_preds = []\n",
    "\n",
    "# Bucle dia a dia per predir de manera autoregressiva\n",
    "for fecha in future_dates:\n",
    "    # Construir un dict X_new amb tots els lag_features\n",
    "    X_new = {}\n",
    "    for f in lag_features:\n",
    "        lag_num = int(f.split(\"Close_lag\")[1])\n",
    "        X_new[f] = last_closes[-lag_num]\n",
    "\n",
    "    # Convertir a DataFrame d’una sola fila\n",
    "    X_new_df = pd.DataFrame([X_new])\n",
    "\n",
    "    # Predir el proper 'Close'\n",
    "    y_pred_fut = modelo_para_futuro.predict(X_new_df)[0]\n",
    "    future_preds.append(y_pred_fut)\n",
    "\n",
    "    # Afegir la predicció a last_closes\n",
    "    last_closes.append(y_pred_fut)\n",
    "\n",
    "# Desar prediccions futures en un CSV\n",
    "df_fut_pred = pd.DataFrame({\n",
    "    \"Date\": future_dates,\n",
    "    \"Predicted_Close\": future_preds\n",
    "})\n",
    "future_csv_path = os.path.join(model_folder, f\"{dataset_name}_future_10days_reduced.csv\")\n",
    "df_fut_pred.to_csv(future_csv_path, index=False)\n",
    "print(f\"  ✓ Prediccions futures (model reduït) desades a: {future_csv_path}\")\n",
    "\n",
    "\n",
    "# Gràfica històric + prediccions futures\n",
    "\n",
    "fig_future = go.Figure()\n",
    "# 13.1) Històric real de 'Close'\n",
    "fig_future.add_trace(go.Scatter(\n",
    "    x=df['Date'],\n",
    "    y=df['Close'],\n",
    "    mode='lines',\n",
    "    name='Històric Close',\n",
    "    line=dict(color='lightblue')\n",
    "))\n",
    "# 13.2) Sèrie de prediccions futures\n",
    "fig_future.add_trace(go.Scatter(\n",
    "    x=future_dates,\n",
    "    y=np.array(future_preds),\n",
    "    mode='lines+markers',\n",
    "    name='Predicció futura (10 dies)',\n",
    "    line=dict(color='orange', dash='dash'),\n",
    "    marker=dict(size=6)\n",
    "))\n",
    "fig_future.update_layout(\n",
    "    title=\"S&P500 – Predicció Propers 10 Dies (Model reduït)\",\n",
    "    xaxis_title='Data',\n",
    "    yaxis_title='Preu Close (USD)',\n",
    "    template='plotly_dark',\n",
    "    xaxis_rangeslider_visible=True\n",
    ")\n",
    "\n",
    "future_plot_path = os.path.join(model_folder, f\"{dataset_name}_future_reduced_plot.html\")\n",
    "fig_future.write_html(future_plot_path)\n",
    "print(f\"  ✓ Gràfica futura (model reduït) desada a: {future_plot_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
